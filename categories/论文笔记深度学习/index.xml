<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>论文笔记——深度学习 - 分类 - 大猫的博客</title>
        <link>https://capablecat.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
        <description>论文笔记——深度学习 - 分类 - 大猫的博客</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>krio_d@protonmail.com (大猫)</managingEditor>
            <webMaster>krio_d@protonmail.com (大猫)</webMaster><lastBuildDate>Sun, 15 Aug 2021 12:10:00 &#43;0800</lastBuildDate><atom:link href="https://capablecat.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>论文笔记——Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0self-promoted-prototype-refinement-for-few-shot-class-incremental-learning/</link>
    <pubDate>Sun, 15 Aug 2021 12:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0self-promoted-prototype-refinement-for-few-shot-class-incremental-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，暂时没有开源代码。 本文研究的问题是 FSCIL，即 few-shot incremental learning。与传统的增量学习问题相比，FSCIL 还面]]></description>
</item><item>
    <title>论文笔记——Training Networks in Null Space of Feature Covariance for Continual Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</link>
    <pubDate>Tue, 27 Jul 2021 20:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。（本文是西交数学与统计学院发表的文章，数学方面比较硬核） 本文专注于连续训练时不访问之前的数据。本]]></description>
</item><item>
    <title>论文笔记——Prototype Augmentation and Self-Supervision for Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</link>
    <pubDate>Tue, 27 Jul 2021 14:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。 本文指出了增量学习过程中 task-level overfitting phenomenon。直观上，这是说模型在训练当前任务的时候，只会专]]></description>
</item><item>
    <title>论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/</link>
    <pubDate>Tue, 20 Jul 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2021，代码见此。 本文聚焦于 rehearsal 策略中样本筛选问题，作者认为，被选择存储在内存中的样本不仅应该代表它们对应的类别，而且应该区]]></description>
</item><item>
    <title>论文笔记——Efficient Feature Transformations for Discriminative and Generative Continual Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/</link>
    <pubDate>Thu, 15 Jul 2021 12:17:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2021，代码见此。 本文基于 architectural strategy，聚焦于提高效率（Efficient），即压缩网络模型，降低模型参数。文]]></description>
</item><item>
    <title>论文笔记——Continual Learning via Bit-Level Information Preserving</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/</link>
    <pubDate>Mon, 28 Jun 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2021，代码见此。 本文从信息论的角度分析了增量学习过程，提出增量学习过程中，模型经验随着模型所看到的数据积累而积累，每个模]]></description>
</item><item>
    <title>论文笔记——DER: Dynamically Expandable Representation for Class Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</link>
    <pubDate>Thu, 24 Jun 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2021，随文代码在这里。 本文主要基于 architectural strategy，设计了一种动态扩充网络模型的方法。同时，该方法也采用了 rehearsal strategy 保]]></description>
</item><item>
    <title>论文笔记——Mnemonics Training: Multi-Class Incremental Learning without Forgetting</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</link>
    <pubDate>Mon, 07 Jun 2021 01:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2020，代码在这里。 本文基于 Rehearsal strategy，从改进样例集的角度出发提出了 Mnemonics Training。他们把旧样例集（exemp]]></description>
</item><item>
    <title>论文笔记——iCaRL: Incremental Classifier and Representation Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</link>
    <pubDate>Mon, 17 May 2021 12:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</guid>
    <description><![CDATA[简介 本文是增量学习的经典论文，发表于CVPR 2017，基于pytorch的代码在此处。 本文是rehearsal策略的经典算法，其核心点主要是]]></description>
</item><item>
    <title>论文笔记——Learning a Unified Classifier Incrementally via Rebalancing</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/</link>
    <pubDate>Thu, 13 May 2021 12:15:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2019，复现代码见此。 LUCIR同样是致力于缓解rehearsal中不平衡问题，如 Fig.1 所示，本文指出不平衡的数据主要带]]></description>
</item></channel>
</rss>
