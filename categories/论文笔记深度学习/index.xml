<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>论文笔记——深度学习 - 分类 - 大猫的博客</title>
        <link>https://capablecat.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
        <description>论文笔记——深度学习 - 分类 - 大猫的博客</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>krio_d@protonmail.com (大猫)</managingEditor>
            <webMaster>krio_d@protonmail.com (大猫)</webMaster><lastBuildDate>Mon, 28 Jun 2021 08:32:00 &#43;0800</lastBuildDate><atom:link href="https://capablecat.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>论文笔记——Continual Learning via Bit-Level Information Preserving</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/</link>
    <pubDate>Mon, 28 Jun 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/</guid>
    <description><![CDATA[简介 本文发表于 NAACL 2021，代码见此。 本文从信息论的角度分析了增量学习过程，提出增量学习过程中，模型经验随着模型所看到的数据积累而积累，每个模]]></description>
</item><item>
    <title>论文笔记——DER: Dynamically Expandable Representation for Class Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</link>
    <pubDate>Thu, 24 Jun 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2021，随文代码在这里。 本文主要基于 architectural strategy，设计了一种动态扩充网络模型的方法。同时，该方法也采用了 rehearsal strategy 保]]></description>
</item><item>
    <title>论文笔记——Mnemonics Training: Multi-Class Incremental Learning without Forgetting</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</link>
    <pubDate>Mon, 07 Jun 2021 01:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2020，代码在这里。 本文基于 Rehearsal strategy，从改进样例集的角度出发提出了 Mnemonics Training。他们把旧样例集（exemp]]></description>
</item><item>
    <title>论文笔记——iCaRL: Incremental Classifier and Representation Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</link>
    <pubDate>Mon, 17 May 2021 12:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</guid>
    <description><![CDATA[简介 本文是增量学习的经典论文，发表于CVPR 2017，基于pytorch的代码在此处。 本文是rehearsal策略的经典算法，其核心点主要是]]></description>
</item><item>
    <title>论文笔记——Maintaining Discrimination and Fairness in Class Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/</link>
    <pubDate>Wed, 12 May 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2020，参考代码见此。 本文主要做了两方面工作：其一，分析了知识蒸馏（Knowing Distillation）在增量学习中实]]></description>
</item><item>
    <title>论文笔记——Large Scale Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/</link>
    <pubDate>Thu, 22 Apr 2021 11:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2019，代码见此。 本文在回溯策略上同 iCaRL 一样遵循了 herding 策略，主要致力于解决 rehearsal strategy 中新旧类不平衡问题，提出在全连接层后面增加]]></description>
</item></channel>
</rss>
