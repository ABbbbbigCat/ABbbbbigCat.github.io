[{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于 CVPR 2021，代码见此。 本文聚焦于 rehearsal 策略中样本筛选问题，作者认为，被选择存储在内存中的样本不仅应该代表它们对应的类别，而且应该区别于其他类别。 为了选择这样的样本，作者认为靠近分类边界的样本最具辨别力，靠近分布中心的样本最具代表性。 为了满足这两个特征，本文提出对特征空间中不同的样本进行采样，提出一种新的多样性感知采样方法，通过利用分类不确定性有效管理容量有限的内存。另外，为了进一步提升样本多样性，本文建议采用 data augmentation。 另外，如 Fig 2 所示，本文针对现实中更可能的增量环境 Blurry-CIL (每次新任务中也会包含少量之前看过的类别，任务与任务之间并非完全隔绝的) 做了研究，探讨了该环境下的增量学习问题。 方法 ","date":"2021-07-20","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/"},{"categories":["论文笔记——深度学习"],"content":"Diversity-Aware Memory Update 为了确保多样性，需要估计每个样本在类别判别特征空间中的相对位置。 但是计算特征的相对位置在计算上是昂贵的，因为它需要计算样本到样本的距离 $(O(N^2))$。 相反，本文建议通过分类模型估计的样本的不确定性来估计相对位置，即假设模型的更确定样本将位于更靠近类分布中心的位置，反之亦然。 Algorithm 1 给出了样例更新的流程，其中公式 4 如上所示。在公式4中，$u(x)$ 表示样本 $x$ 的不确定性，$S_c$ 是类别 $c$ 是预测的 top-1 类别的次数。$1_c$ 表示二进制索引向量。 值较低的 $u(x)$ 对应于扰动上更一致的 top-1 类，表明 $x$ 位于模型非常自信的区域。 公式 4 的思想很直观，如 Fig 3 所示，对输入施加扰动，然后计算扰动样本 $\\tilde{x}$ 被推断为正确类的次数 $S_c$，最后计算得到 $u(x)$。显然，$Sc$越大，$u(x)$越小，从而不确定性越小。 ","date":"2021-07-20","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/:1:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/"},{"categories":["论文笔记——深度学习"],"content":"Diversity Enhancement by Augmentation ","date":"2021-07-20","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/:2:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/"},{"categories":["论文笔记——深度学习"],"content":"Mixed-Label Data Augmentation 随着任务迭代的进行，新任务中的样本可能遵循与情景记忆中的样本（即之前的任务）不同的分布。RW采用混合标记的 DA (data augmentation) 来“混合”新任务类中的图像和内存中旧类的样本。 这种混合标签 DA 减轻了由任务上的类分布变化引起的副作用并提高了性能。 作为代表性的混合标记 DA 方法之一，CutMix [1] 生成混合样本和平滑标签，给定一组监督样本 $(x1, y1)$ 和 $(x2, y2)$，如下所示： 其中，集合 $m$ 表示根据从beta分布中提取的超参数$β$为图像x1随机选择的像素区域。如（5）所示，混合标签DA生成的人工样本很难被视为源图像的变体，这与传统数据增强不同，传统数据增强在不破坏类边界的情况下通过翻转、旋转和/或对比操作原始图像。 Automated Data Augmentation. 除了上述混合标记的 DAs 之外，RW进一步使用 AutoDA 通过在 CIL 下将多个 DA 合成到模型性能上来丰富增强效果。 特别是，文章采用 AutoAugment [2]，提供用于确定增强次数及其幅度的参数。（[2] 就是一种自动化增强数据的方法） 实验 参考 Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. In ICCV, pages 6023–6032, 2019. Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V. Le. AutoAugment: Learning augmentation strategies from data. In CVPR, June 2019. ","date":"2021-07-20","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/:2:1","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于CVPR 2021，代码见此。 本文基于 architectural strategy，聚焦于提高效率（Efficient），即压缩网络模型，降低模型参数。文章照例分析了现有的三种主流策略：rehearsal，regularization和archetectural。指出rehearsal受制于memory buffer，模型新旧任务间的bias严重；regularization则会限制模型的scalability且regularization通常猜想参数的重要性是独立的，而忽略了参数间的相关性（从底层角度，这是因为神经网络的黑盒特性）。而architectral可以从设计（design）上缓解灾难性遗忘，且根据新任务扩充网络可以保证模型的scalability（维护模型结构同时可能避免性能的unintentional degradation，因为许多模型诸如超参数设置等都是在工程上精心设计过的）。而architetural的的一个主要的缺陷是参数量大、性能消耗大，所以本文提出了一种新的特征变换方法，为其命名为 EFT （Efficient Feature Transformation）。 方法 本文将参数分成了glbal parameter $\\theta$和task-specific local parameter $\\tau_t$，在训练任务t时，$\\theta$和$\\tau_{1:t-1}$保持不变，只有$\\tau_t$被训练。Fig 1 center 是另一种参数化方法，它并行计算这些特征校准，使变换增加而不是合成。公式如下： $$H^{'}=(WI)\\bigoplus(\\tau^l_tI)$$ 其中$\\bigoplus$是增加（addition），$\\tau^l_t$是$l-layer$的 task-specific parameter。 ","date":"2021-07-15","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/:0:0","tags":["incremental learning","architectural strategy"],"title":"论文笔记——Efficient Feature Transformations for Discriminative and Generative Continual Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/"},{"categories":["论文笔记——深度学习"],"content":"2D Convolution Layer 简而言之，EFT设计了两类卷积核 $w^s \\in 33a$和$w^d\\in11b$分别用于计算特征的空间信息和深度信息。对于一个特征$F$，EFT将其分成了 $K/a$和$K/b$个group，每个group都有对应的$w^s$和$w^d$，将这些分割的特征通过concatenat，并将利用公式$H=H^s+\\gamma H^d$就能空间信息和深度信息合成一个完整的feature map $H$了，它的结构与正常卷积的结构一致。公式中$\\gamma \\in {0,1}$用以指示是否使用 $w^d$。 ","date":"2021-07-15","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/:1:0","tags":["incremental learning","architectural strategy"],"title":"论文笔记——Efficient Feature Transformations for Discriminative and Generative Continual Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/"},{"categories":["论文笔记——深度学习"],"content":"Fully Connected Layer 和卷积层一样，EFT也设计task-speicfic fully conneted layer，即通过另一个全连接层（由$E$参数化）将输出向量$F$转换为特定于任务的特征向量H。公式为$h=Ef$，为了节省计算开销，其中的$E$为对角矩阵，这让该公式实现了一个Hadamard product。 ","date":"2021-07-15","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/:2:0","tags":["incremental learning","architectural strategy"],"title":"论文笔记——Efficient Feature Transformations for Discriminative and Generative Continual Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/"},{"categories":["论文笔记——深度学习"],"content":"Task Prediction 对于CIL这种情况，本文采用了通过分类时的最大置信度预测（maximum confidence prediction）的来选择$\\tau_t$。然而，由于典型的交叉熵训练目标倾向于在确定性神经网络中产生高置信度（即使对于分布外（OoD, out-of-distribution）样本），故softmax预测熵的简单直接测量通常表现不佳[1]。为了解决这个问题，本文提出了一种简单的正则化方式来最大化特征距离，以提高任务预测能力: $$L_M=\\sum_{i=1}^{t-1}max(\\Delta-KL(P_t||Q_i),0)$$ 其中 $P_t = N(μ_t,Σ_t) $和 $Q_i = N(μ_i,Σ_i)$ 是当前任务$t$ 和较早任务 $i \u003c t$ 的分布。 该正则化项帮助模型学习 $τ_t$ 的表示，使得当前任务数据 ($D_t$) 在特征空间中与由先前任务的参数 $τ\u003ct$ 编码的特征至少具有$∆$可分离性。 所以，最终的损失函数为：$L_{EFT} =L(yˆ,y)+λL_M$ 实验 整体而言，本文在想法上基本遵循了之前的思想，并无太大创新，其内核和建筑化策略一致。但本文聚焦于计算效率问题，很大幅度的降低了参数增长，这是本文工作中最杰出的部分。至于建筑化的一些关键缺陷，比如推断时如何找到对应网络，本文依旧没有提出有效的解决方法。（Table 5 说明了$L_m$有作用，但效果很不明显。显然，基于置信度筛选还是非常容易翻车的） 参考 [1] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein- berger. On calibration of modern neural networks, 2017. 4 ","date":"2021-07-15","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/:3:0","tags":["incremental learning","architectural strategy"],"title":"论文笔记——Efficient Feature Transformations for Discriminative and Generative Continual Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0efficient-feature-transformations-for-discriminative-and-generative-continual-learning/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于 CVPR 2021，代码见此。 本文从信息论的角度分析了增量学习过程，提出增量学习过程中，模型经验随着模型所看到的数据积累而积累，每个模型的参数推断也应该逐渐趋于确定（数据量的增加使得参数空间逐渐减小，确定性增加，熵减少）。这样，增量学习实际是由顺序传入的任务所驱动的一个递归的学习模型参数信息的过程。从这个观点来看，遗忘可以被理解为先前任务数据提供的关于模型参数信息的丢失。 为了更加直观的研究信息增益（IG, Information Gain），本文对模型参数进行了量化（例如20位字节）让参数以字节的形式展现。对于一个参数而言，在之前的训练中已经确定的位如果在之后的训练中发生了翻转，就意味着舍弃了之前所学习到的信息，从而发生了遗忘。 就本质而言，本文的思想和EWC等正则化方法一致，都是认为确定性高的参数在增量过程中发生改变意味着舍弃过去知识。不过本文通过将参数表示为字节形式，降低了颗粒度，并基于字节形式利用香农熵的变化从数学的角度推断出需要被冻结的bit。这使得本文在思路上和方法上都给人一种耳目一新的感觉。 据此，本文提出了一种新的位级信息保存（BLIP, Bit-level Information Preserving）方法，该方法通过位冻结对模型参数进行量化，并直接保留先前学习任务带来的模型参数信息增益。 bit-level 指的是将权重转换为字节的形式，以高位到地位的顺序逐渐固定字节。相较于freeze parameter，freeze bit 拥有更细的颗粒度， Bit-level Information Preserving Algorithm 1 给出了完整算法 ","date":"2021-06-28","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/:0:0","tags":["incremental learning","regularization strategy"],"title":"论文笔记——Continual Learning via Bit-Level Information Preserving","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/"},{"categories":["论文笔记——深度学习"],"content":"所以应该怎样 freeze bit 呢？ 论文的 section 4.4 给出了在 Information Gain 指导下的 Bit Freezing。信息增益，即学习任务$D_t$后香农熵的减少，因此可以近似的等于过程中$Q(\\theta,N)$里有多少更多的bit被确定。这些特定位继续翻转（flip）意味着丢弃已有的信息增益，故需将其冻结。其公式如下： $$n_t=\\lceil IG(Q(\\theta,N),D_t)\\rceil$$ 此外，由于 $\\theta$ 上的后验是高斯分布，并且只会在局部变得峰值和集中，因此 $Q(θ, N)$ 中的位从较高的有效位到较低的有效位开始变得确定。 相关的公式如下： $$IG(Q(\\theta,N),D_t)=H(Q(\\theta_{0:t-1},N))-H(Q(\\theta_{0:t},N))$$ $$H(Q(\\theta,N))=-\\sum_{i=1}^{2^N}P(Q(\\theta,N)=q_i)log_{2}P(Q(\\theta,N)=q_i)$$ $$Q(\\theta,N)=\\frac{\\lfloor(2^Nmin(max(\\theta,-1+\\frac{1}{2^N+1}),1-\\frac{1}{2^N+1}))\\rceil}{2^N},其中\\lfloor~·\\rceil将数字舍入到最接近的整数$$ 其中$q_i$代表$Q(\\theta,N)$在$i$-$th$可能的取值，$N$是位数。为了顺利求导，本文使用了直通估计器（ Straight Through Estimator, STE）[1]，将$Q$的梯度近似为$\\frac{\\partial Q(\\theta,N)}{\\theta}=1$。 实验结果 实验结果显示准确率非常高，对于一个没使用 rehearsal 的方法而言这简直是质的飞跃。不过，当看到 Benchmarks and Models 中的\"task identity is given during both training and evaluation\"，我意识到实际的测试可能要依据task-id。仔细阅读代码后发现本文采用了 multi-head classifier，所以这个准确率比较正常。本文最有趣的地方还是提出的视角颇为新颖。 ","date":"2021-06-28","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/:1:0","tags":["incremental learning","regularization strategy"],"title":"论文笔记——Continual Learning via Bit-Level Information Preserving","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0continual-learning-via-bit-level-information-preserving/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于CVPR 2021，随文代码在这里。 本文主要基于 architectural strategy，设计了一种动态扩充网络模型的方法。同时，该方法也采用了 rehearsal strategy 保存了旧数据的样例集 $M_t$ 用于未来训练（基于 herding 方法）。在思想上，本文遵循了 architecture 和 rehearsal 策略，完全固定提取到的特征并用留存数据和新数据对其进行训练来获得分类器。在性能上，DER能够获取十分不错的准确率，但不断扩充的模型和 super feature 会让模型的容量不断增大。 模型结构 训练过程 具体而言，DER在每次增量时固定之前学习到的特征提取器，并且学习一个新的、基于新数据 $D_t$ 和留存数据 $M_{1:t-1}$ 训练的特征提取器来扩充模型。对于新特征提取器，DER使用了一个辅助损失函数 $L_{H_{t}^a}$ 来学习 $D_t$ 和 $M_{1:t-1}$ 的差异性，并利用一个 Mask layer 对特征提取器的channel进行减枝以学习compact feature。最终，DER将新学习到的特征提取器所提取到的特征embed到之前所学习到的特征中构成 super feature，重新初始化和训练模型分类器。 所以，该模型的最终的损失函数为： $$ L_{DER}=L_{H_t}+\\lambda_aL_{H_t^a}+\\lambda_sL_S$$ $$ L_s = \\frac{\\sum_{l=1}^LK_l||m_{l-1}||_1||m_l||_1}{\\sum_{l=1}^LK_lc_{l-1}c_l}$$ 其中，$L-\u003e总层数, K_l-\u003el卷积层的核大小，c_l-\u003el层的通道数$。$m_l=\\sigma(se_l)$，$e_l$是可学习掩码参数，$s$是一个比例因子（scaling factor）用于控制公式的锐度（sharpness），有：$s=\\frac{1}{s_{max}}+(s_{max}-\\frac{1}{s_{max}})\\frac{b-1}{B-1}$，$s_{max}»1$是一个超参数，$b$是批量索引（batch index），$B$是一次epoch中的批量总数。显然，$b$的变化引起了$s$的变化。（注意到对$\\sigma(se_l)$求导时，得到的结果为$g_{el}=s\\sigma(se_l)[1-\\sigma(se_l)]$会受$s$的变化影响而不稳定，故本文提出了利用$g_{el}^{'}=\\frac{\\sigma(e_l)[1-\\sigma(e_l)]}{s\\sigma(se_l)[1-\\sigma(se_l)]}g_{e_l}$对其进行补偿）。 $L_s$是一个Sparsity Loss，其大小受 $m_l$的影响，$m_l$越稀疏，$L_s$ 越小。稀疏的 $m_l$ 可以实现对特征提取层的剪枝。就个人当前的知识面而言，$L_s$ 的设计很是巧妙 实验结果 模型：对于 CIFAR-100 和 ImageNet 都采用 18-layer ResNet 作为基本模型，细节上遵循 RPSNet 任务设置：本文对两种主流的任务设置方式都进行了实现：其一，每次增量 N 个类（文中以 B0 表示）；其二，初始训练数据集一半的类，之后每次增量 N 个类（文中用 B50 表示） 数据留存：固定大小 $M = 2000$ ","date":"2021-06-24","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/:0:0","tags":["incremental learning","architectural strategy","rehearsal strategy"],"title":"论文笔记——DER: Dynamically Expandable Representation for Class Incremental Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/"},{"categories":["算法笔记"],"content":"总览 这个月 Leetcode 彷佛开启了背包专场，连着数天都是经典的背包问题。于是我在这里决定就背包问题进行整理，记录个人心得。这里整理的是最为常见的0-1背包、完全背包和多重背包。 0-1 背包问题 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:0:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"1. 问题描述 这是最经典的背包问题，题目的风格概括而言可以是：一堆有限的物品（物品不一定非得是一个，只要有限都可以简化为0-1背包问题），每个物品有其对应的价值，然后有一个容积一定的容器，问怎么装才能获得最大价值。 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:1:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"2. 问题分析 先从为什么这个题可以用动态规划解决说起：动态规划指一个较复杂的求优问题可以拆解为若干个相互联系的阶段，每个阶段的决策需要考虑当前所处状态，且该阶段的决策会影响之后的决策。 背包问题中，需要考虑的状态主要是当前可选物品和当前可用空间，据此我们推导出状态矩阵应当是$dp[i][V]$，它表示在可选物品为$[0, i-1]$、可用空间为$volume$时可以获取的最大价值。进一步的，我们定义状态转移矩阵 : $$dp[i][V]=max(dp[i-1][V-w[i]]+v[i], dp[i-1][V])$$ 上式中，$i$代表物品的编号，$V$代表容器当前的体积，$v$代表物品的价值，$w$数组中记录着物品所占体积。该状态转移矩阵比较了新物品引入时，装入它和不装入它所获得的价值大小，从而推导出当前阶段的最优解。观察该状态转移矩阵不难发现，当前阶段的结果只与$i-1$阶段有关，所以只要保证逆序推导，即使省略掉**$i$维度**的数据也是可行。 最终，核心循环如下: // n 代表商品数目 for(int i = 0; i \u003c n; ++i){ for(int j = V; j \u003e= w[i]; --j) dp[j] = max(dp[j], dp[j - w[i]] + v[i]); } 例题：Leetcode-416，Leetcode-1049 上述两题与传统背包问题的区别在于：传统问题要求选择的物品不能超过给定的容积，而Leetcode-416必须恰好等于总容积的一半，Leetcode-1049是必须尽可能接近一半。至于价值，物品的价值就是物品自身的值。 完全背包问题 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:2:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"1. 问题描述 概括描述：有多类商品且数目不限，第$i$类物品的价值为$v[i]$，重量为$w[i]$，怎样把它们装进一个容积一定的容器才能获得最大的价值。 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:3:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"2. 问题分析 完全背包和0-1背包最大的区别就是物品的数目不限，但依阶段逐步推优的思路是不变的，只是引入当前商品后，我们可以继续考虑当前商品是否可以装入容器。所以我们仍然可以写出状态转移矩阵: $$dp[i][V]=max(dp[i][V-w[i]]+v[i], dp[i-1][V])$$ 与0-1背包问题一样，这个二维矩阵也可以转换为一维矩阵。观察上式不难发现：若要装入当前商品，那么结果只与考虑了当前商品的结果有关；不装入商品，则结果只与未考虑当前商品的结果有关。因此只要保证顺序推导，我们就能将其简化为一维数组。 最终，核心循环如下: // n 代表商品数目 for(int i = 0; i \u003c n; ++i){ for(int j = 0; j \u003c= V; ++j){ if(j \u003e= w[i]) dp[j] = max(dp[j], dp[j - w[i]] + v[i]); } } 例题：Leetcode-377，Leetcode-硬币，Leetcode-1449 除了求最大价值，一种十分常见的问题是求组合数，上述的前两题均是如此 多重背包问题 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:4:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"1. 问题描述 概括描述：有多类物品，第$i$类物品的价值为$v[i]$，重量为$w[i]$，数目为$n[i]$，问如何把它们装进一个容积一定的容器中，才能使获得的价值最大。 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:5:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法笔记"],"content":"2. 问题分析 一个很朴素但又很有效的方法是把这类问题作为 0-1 问题的拓展，将其的种类总数看作 $种类数目*每类数目$，之后用 0 - 1背包的解法即可。 延伸问题：多维背包 之前讨论中，背包只有一个限制即背包的重量，如果引入新的限制，那么一维背包问题也就延伸为多维背包问题。对于这种问题，一个基本的思想是：有多少限制，加多少维度。然后再用一维背包问题的思想去解决 例题: Leetcode-879 本题中属于二维的0-1背包问题，在确定了员工数和收益这两个维度的限制后，套用0-1背包的思想，保证逆序推导即可得出答案 ","date":"2021-06-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:6:0","tags":["动态规划","背包问题"],"title":"算法笔记——背包问题","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于 CVPR 2020，代码在这里。 本文基于 Rehearsal strategy，从改进样例集的角度出发提出了 Mnemonics Training。他们把旧样例集（exemplars）进行了参数化，在训练过程中从两个层面进行优化：模型层面，数据层面。即不仅模型的参数是可学习的，留存的数据也是可学习的。 训练的思想就是同时优化模型参数和留存数据（交替优化），让模型在数据集上的loss尽可能小。 提出 Mnemonics 的背景是其他数据筛选方式（herding, random）的性能并不算好，作者利用TSNE可视化（见fig.1）指出 Mnemonics 相较而言能更好地保存数据的边界信息。（其实这个说法有些奇怪，毕竟对于 herding 而言，其留存的数据集靠近中心是正常现象，因为它就是基于均值进行采样的。不过本文最后的实验结果确实较好，这佐证了作者的论证） 训练过程 $$L_{all} = \\lambda L_c(\\Theta_i;\\varepsilon_{0:i-1}\\bigcup D_i)+(1-\\lambda)L_d(\\Theta_i;\\Theta_{i-1};\\varepsilon_{0:i-1}\\bigcup D_i) \\tag{5}$$ $$\\Theta_{i}\\leftarrow\\Theta_i-\\alpha_1\\nabla L_{all} \\tag{6}$$ $$\\varepsilon_i\\leftarrow\\varepsilon_i-\\beta_i\\nabla_{\\varepsilon}L_c(\\Theta_i^{'};D_i) \\tag{9}$$ $$\\varepsilon_{0:i-1}^{A}\\leftarrow\\varepsilon^A_{0:i-1}-\\beta_2\\nabla_{\\varepsilon^A}L_c(\\Theta^{'}_i(\\varepsilon^A_{0:i-1});\\varepsilon^B_{0:i-1}) \\tag{10a}$$ $$\\varepsilon_{0:i-1}^{B}\\leftarrow\\varepsilon^B_{0:i-1}-\\beta_2\\nabla_{\\varepsilon^B}L_c(\\Theta^{'}_i(\\varepsilon^B_{0:i-1});\\varepsilon^A_{0:i-1}) \\tag{10b}$$ 其中，$L_c$是 softmax交叉熵损失，$L_d$是蒸馏损失。这里的$\\Theta_i^{'}$是用$\\varepsilon$训练一个临时模型以最大化对$D_i$的预测。之后固定$\\Theta_i^{'}$即可实现对数据集的优化。公式10把留存的样例集分为两个子集，分别作为对方的验证集。 训练流程很清晰：在优化模型参数$\\Theta$时，同时计算了交叉熵损失和蒸馏损失；而优化样例集$\\varepsilon$时，只计算了交叉熵损失。利用一个临时模型$\\Theta_i^{'}$来优化样例集的优势在于，这能使得保留的数据理论上包含更多旧模型知识——**对于$\\varepsilon_i$而言，$\\Theta_i^{'}$基于$D_i$优化，所以以其为参数优化样例集$\\varepsilon_i$可以使$\\varepsilon_i$包含更多的$D_i$的特征；对于$\\varepsilon_{0:i-1}$而言，基于$\\Theta_i^{'}$的优化可以让它们集成$D_i$的特征**。 个人感受：本文有趣的地方就在于利用训练好的模型去优化留存的数据，从而让数据更具代表性。不过使用最新的模型去优化以前留存的数据，这带来的一个直观问题是：旧数据虽然集成了新模型的知识，但理论上却也损失了其对旧数据的代表性。 模型框架 下图直观的展示了本文的核心部分——如何训样例集$\\varepsilon$。 实验结果 以一半的类作为第一次训练的基准，之后按照阶段 N = 5, 10, 25 进行增量训练 ","date":"2021-06-07","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Mnemonics Training: Multi-Class Incremental Learning without Forgetting","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/"},{"categories":["Unity3d开发笔记"],"content":"Unity3d 使用Spine动画 Spine 是一款针对 2D 骨骼动画编辑工具。与传统的逐帧动画相比，Spine 动画由于只保存骨骼的动画数据，它所占用的空间非常小。对于程序而言，可以通过代码控制骨骼，实现程序动画。SkeletonAnimation 是 Spine 引入的重要组件。 基本使用方法可参考CSDN上的一篇博客，更细致的使用可参看官方文档中的\"怎么使用SkeletonAnimation\"。 教程：Spine 示例项目 Unity3d 进度条 设置 unity3d 的进度条，最常见的一种手段是将图片属性栏的 “Image Type” 属性设置为 “Filled”，通过对图片进行填充来模拟进度条。多数情况下，这是个不错的选择。但当图片素材本身在拉伸时会变形时，这个方法就不太好用了。 这个时候，我们可以通过改变图片 “Rect Transform” 中的 “Pivot” 后通过改变图片的 “Scale” 来实现进度条效果。当然在这之前我们需要把图片属性设置为 “Sliced”，并利用 “Sprite Editor” 改变图片的九宫格属性，以确保其拉伸时不会发生形变。 如果存在进度条特效，只需要关注进度条特效的位置，使其变化与进度条保持一致即可 Unity3d 文件引用拷贝 在开发过程中，我们有时会碰到接手长期活动的新一期开发工作。这个时候我们会用到上一期活动的文件。直接拷贝并不可取，因为这会使拷贝内容仍旧依赖于上一期文件。这个时候就需要利用到Unity3d的中引用拷贝了。对需要拷贝的文件右击，并按照如下方式拷贝，就能实现引用拷贝了。 ","date":"2021-06-02","objectID":"/unity3d%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/:0:0","tags":["Unity3d开发技巧"],"title":"Unity3d开发笔记——常用功能（持续更新…）","uri":"/unity3d%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/"},{"categories":["算法笔记"],"content":"例题：leetcode-5 1. 引子 在一串字符串里找出最长回文串的问题，可以通过暴力求解法来解决，其时间复杂度为O(n^2)，这当然不会很快。算法的设计，就是为了让计算机能够更加高效地处理问题。我们希望可以降低时间复杂度，在1975一位名叫Manacher的人提出了这种算法，虽然牺牲了空间复杂度，让时间复杂度降为O(n) 2. 算法细节 ","date":"2021-06-02","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/:0:0","tags":["回文串"],"title":"算法笔记——马拉车算法(Manacher's Algorithm)","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/"},{"categories":["算法笔记"],"content":"2.1 预处理 马拉车算法首先对我们输入的默认字符串进行一次预处理，即给所有字符的左右两边添加上一个相同的符号，比如“#”。假设原始字符串为\"aabca\"，那么预处理过后就变成了“#a#a#b#c#a#”。为什么要这样做？我们在寻找最长字符串时，要做的事情就是以某一个值或者两个值为中心，向两边扩展，去对比左右两边的值是否匹配。这里就会有一个问题，取决于回文串本身是奇数还是偶数，相应的中心可能是一个值或者两个值。通过添加额外字符，让所有回文串都变为奇数，这就简化了寻找基准。不过这也相应的让空间复杂度由O(1)变为了O(n)。 原字符（奇）：aba 添加额外字符后（奇）：#a#b#a# 原字符（偶）：bb 添加额外字符后（奇）：#b#b# 不过只是添加了“#”还不够，为了能够准确地区分出字符串的头部和尾部，避免搜索时出现下标溢出的情况，需要在字符串头部和尾部分别添加一个与“#”和原始字符不同的字符，保证这俩字符永远也不会和其他字符组合成回文串。这里我们给头部添加一个符号“^”，给尾部添加一个符号“%”。这样，完整的处理效果如下： 处理后字符串：^#a#b#a#% ","date":"2021-06-02","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/:1:0","tags":["回文串"],"title":"算法笔记——马拉车算法(Manacher's Algorithm)","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/"},{"categories":["算法笔记"],"content":"2.2 算法描述 已经对原始字符串做完预处理，现在可以开始找最长字符串了。这里引入几个概念： $C$——中心值的下标，要求以其为下标时，半径$R$必须最大 $P[i]$——（除开首尾字符）以各个字符为中心时，相应的最长半径 $R$——以$C$为中心时，其右端最远处的下标值。计算方式为 $P[C]+C$ $Start$——最长字符串（在原始字符串中）起始索引。计算方式为 $(C-P[C])/2$ 想要找到最长字符串，其实就是去找到拥有最大半径的那个中心点。另外，通过比较所有$P[i]$的值，可以得到拥有最长半径的MaxLen及最长半径P[MaxLen]和起始索引start，那么就可以准确定位最长字符串的位置了。 接下来就开始遍历搜索吧，不过别急，这里我们可以借助回文的特性，通过一些额外的技巧让搜索更具效率。 这个技巧的核心理念是：如果已经发现了长回文，那么包含在长回文中的左边的短回文在右边肯定也是短回文。 这里其实利用了对称的想法，假若我们此刻的中心点为$C$，迭代的指针为$i$，那么右边的$i$相对于中心点$C$在左边应该可以找到一个相对的点 $i_{mirror}$： $i_{mirror}$——与$i$相对于$C$对称。计算方式为 $2*C-i$ 考虑$i$与$R$的关系： $i\u003cR$ 考虑$i_{mirror}$，可以为$P[i]$附上一个初始值。 $P[i_{mirror}] + i\u003c =R$ 令$P[i] = R - i$ （因为超过了中心$C$的管辖范围，我们无法判断超出部分是否与之前的值能够形成回文，所以从超出部分开始匹配搜索） 否则，令$P[i]=P[i_{mirror}]$ $i==R$，无需考虑$i_{mirror}$，直接令$P[i]=0$开始进行扩展。 无需考虑$i\u003eR$，因为一旦出现更大的$R$，$C$就需要更新。这就保证$i$所指向的值至少等于$R$ 在确定$P[i]$的值后，以此为基础确认左右两端的下标值进行扩展搜索，可以有效节约搜索时间。 #include\u003ciostream\u003e#include\u003calgorithm\u003e#include\u003cstring\u003eusing namespace std; string preProcess(string s) { int n = s.length(); if (n == 0) { return \"^%\"; } string ret = \"^\"; for (int i = 0; i \u003c n; i++){ ret += \"#\"; ret += s[i]; } ret += \"#%\"; return ret; } string LongestPair(string s){ if(s==\"\") return s; string S = preProcess(s); int n = S.size(); int P[n]; int C=0, R=0; for(int i=1; i\u003cn-1; ++i){ int i_mirror = 2*C - i; if(R\u003ei){ P[i]=min(R-i, P[i_mirror]); //P[i_mirror]+i\u003eR时，取R-i； } else{ P[i]=0; // 等于R的情况 } // 确定了P[i]的值后，开始进行中心扩展 while (S[i+1+P[i]] == S[i-1-P[i]]){ P[i]++; } // 判断是否需要更新 R if (i + P[i] \u003e R) { C = i; R = i + P[i]; } } // 找出 P 的最大值并计算相应的初始索引 int centerIndex = 1; for (int i = 2; i \u003c n - 1; i++) { if (P[i] \u003e P[centerIndex]) { centerIndex = i; } } int start = (centerIndex - P[centerIndex]) / 2; //起始索引值 return s.substr(start, P[centerIndex]); } ","date":"2021-06-02","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/:2:0","tags":["回文串"],"title":"算法笔记——马拉车算法(Manacher's Algorithm)","uri":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/"},{"categories":["OpenGL学习笔记"],"content":"1. 深度测试 深度测试通过衡量物体的深度缓冲（Depth Buffer, 物体与视口的差距）决定了最后渲染的图像。OpenGL支持八种深度测试函数，其中最长使用的是GL_LESS，效果是“在片段深度值小于缓冲的深度值时通过测试”。OpenGL默认情况下，深度测试是关闭的，需要通过glEnable(GL_DEPTH_TEST)开启。 某些情况下我们会需要对所有片段都执行深度测试并丢弃相应的片段，但不希望更新深度缓冲。这个时候我们可以将glDepthMask()设置为GL_FALSE。此时的深度缓冲是只读的，它可以帮助我们进行深度测试，但不会对深度图进行更新。 深度测试实际采取的并非线性计算$F_{depth}=(z-near)/(far-near)$（在透视矩阵应用之前在观察空间中是线性的），而是非线性计算，其公式如下所示: $$F_{depth}=(1/z-1/near)/(1/far-1/near)$$ 与线性相比，非线性计算中深度值很大一部分是由很小的z值所决定的，这给了近处的物体很大的*深度精度*。这个（从观察者的视角）变换z值的方程是嵌入在投影矩阵中的，所以当我们想将一个顶点坐标从观察空间至裁剪空间的时候这个非线性方程就被应用了。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:0:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"1.2 提前深度测试 现在大部分的GPU都提供一个叫做提前深度测试(Early Depth Testing)的硬件特性。提前深度测试允许深度测试在片段着色器之前运行。只要我们清楚一个片段永远不会是可见的（它在其他物体之后），我们就能提前丢弃这个片段。 片段着色器通常开销都是很大的，所以我们应该尽可能避免运行它们。当使用提前深度测试时，片段着色器的一个限制是你不能写入片段的深度值（通过修改GL_FragDepeth的值）。如果一个片段着色器对它的深度值进行了写入，提前深度测试是不可能的。OpenGL不能提前知道深度值。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:1:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"1.1 深度冲突 一个很常见的视觉错误会在两个平面或者三角形非常紧密地平行排列在一起时会发生，深度缓冲没有足够的精度来决定两个形状哪个在前面。结果就是这两个形状不断地在切换前后顺序，这会导致很奇怪的花纹。这个现象叫做深度冲突(Z-fighting)，因为它看起来像是这两个形状在争夺(Fight)谁该处于顶端。 缓解深度冲突一些简单且易于实现的技巧有： 永远不要把多个物体摆得太靠近，以至于它们的一些三角形会重叠。 尽可能将近平面设置远一些。深度缓冲公式中精度在靠近近平面时是非常高的，所以如果我们将近平面远离观察者，我们将会对整个平截头体有着更大的精度。然而，将近平面设置太远将会导致近处的物体被裁剪掉，所以这通常需要实验和微调来决定最适合你的场景的近平面距离。 另外一个很好的技巧是牺牲一些性能，使用更高精度的深度缓冲。大部分深度缓冲的精度都是24位的，但现在大部分的显卡都支持32位的深度缓冲，这将会极大地提高精度。 2. 模板测试 模板测试(Stencil Test)允许我们根据一些条件丢弃特定片段。当片段着色器处理完一个片段之后，模板测试会开始执行，和深度测试一样，它也可能会丢弃片段。接下来，被保留的片段会进入深度测试，它可能会丢弃更多的片段。模板测试是根据又一个缓冲来进行的，它叫做模板缓冲(Stencil Buffer，通常每个模板值是8位)，我们可以在渲染的时候更新它来获得一些很有意思的效果。（比如战旗类游戏的角色边框等） 模板测试提供了和深度测试中glDepthMask()一样效果的函数： glStencilMask(0xFF); // 每一位写入模板缓冲时都保持原样 glStencilMask(0x00); // 每一位在写入模板缓冲时都会变成0（禁用写入，保证模板图是只读的） 模板测试主要通过glStencilFunc(GLenum func, GLint ref, GLuint mask)和glStencilOp(GLenum sfail, GLenum dpfail, GLenum dppass)这两个函数，其参数具体定义可以在这里得到。前者描述了描述了OpenGL应该对模板缓冲内容做什么，后者则说明应该如何更新模板缓冲。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:2:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"2.1 物体轮廓 模板缓冲一个直接的效果就是帮助我们绘制物体边框。其基本思路是借助模板缓冲在同义词渲染循环中对同一物体进行两次渲染。第一次渲染开启模板测试并更新模板缓冲；第二次渲染将物体的尺寸增大一些，以第一次渲染的模板缓冲为判断基准，关闭模板缓冲更新（正常渲染保存的模板缓冲就是我们所需要的模板缓冲）和深度测试（第二次渲染主要是为了描边，这与深度无关）后渲染物体。 glEnable(GL_STENCIL_TEST); // 在循环之外要先开启深度测试 glStencilFunc(GL_KEEP, GL_KEEP, GL_REPLACE); // 告诉OpenGL在不同情况对模板缓冲做什么 ... // 渲染循环 while { ... glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT); // 清理颜色缓冲值/深度缓冲值/模板缓冲值 ... glStencilFunc(GL_ALWAYS, 1, 0xFF); // 总是能够通过模板测试，这样得到的缓冲图能够描述物体的形态 glStenciMask(0xFF); // 第一次渲染要更新模板缓冲 normalShader.use(); draw(); ... glStenciFunc(GL_NOTEQUAL, 1, 0xFF); // 测试值与模板缓冲值不同时，能够通过模板测试(即尺寸放大后多出来的部分) glStenciMask(0x00); // 禁止更新模板缓冲 glDIsable(GL_DEPTH_TEST); // 关闭深度测试，因为这一次渲染不需要考虑深度，值需要描边 shaderSingleColor.use(); draw(); glStencilMask(0xFF); // 保证模板缓冲可以被glClear()清除 glEnable(GL_DEPTH_TEST); ... } 3. 混合 OpenGL中，混合(Blending)通常是实现物体透明度(Transparency)的一种技术。透明就是说一个物体（或者其中的一部分）不是纯色(Solid Color)的，它的颜色是物体本身的颜色和它背后其它物体的颜色的不同强度结合。物体的透明度由alpha值决定，alpha颜色值是颜色向量的第四个分量。混合的开启仍然需要调用glEnable(GL_BLEND)。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:3:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"3.1 丢弃片段 对于部分全透明但部分不透明的物体（如草），可以选择直接丢弃透明片段而不是混合，这样可以避免深度测试和混合一起时产生一些的麻烦（当写入深度缓冲时，深度缓冲不会检查片段是否是透明的，所以透明的部分会和其它值一样写入到深度缓冲中。如果我们先绘制透明物体再绘制不透明物体，那么无法通过深度测试的不透明物体将会被直接丢弃）。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:4:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"3.2 混合 OpenGL中的混合通过下面这个方程实现： $$\\bar{C}{result}=\\bar{C}{source}∗F_{source}+\\bar{C}_{destination}∗F_{destination}$$ $\\bar{C}_{source}$ ：源颜色向量。这是源自纹理的颜色向量。 $\\bar{C}_{destination}$ ：目标颜色向量。这是当前储存在颜色缓冲中的颜色向量。 $F_{source}$：源因子值。指定了alpha值对源颜色的影响。 $F_{destination}$：目标因子值。指定了alpha值对目标颜色的影响。 OpenGL中的glBlendFunc(GLenum sfactor, GLenum dfactor)函数接受两个参数，来设置源和目标因子。并进一步提供了glBlendFuncSeparate(GLenum sfactorRGB, GLenum dfactorRGB, GLenum sfactorAlpha, GLenum dfactorAplha)为RGB和alpha通道分别设置不同的选项。 OpenGL的混合具有很强的灵活性，glBlendEquation(GLenum mode)允许我们设置运算符。默认情况下mode被设置为GL_FUNC_ADD，表示将两向量相加（这足以令我们应付绝大多数场景渲染）。如果我们想让最终的结果为两向量相减，可以用GL_FUNC_SUBTRACT, GL_FUNC_REVERSE_SUBTRACT，前者是顺序相加（源-目标），后者为逆序。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:5:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"3.3 不要打乱顺序 为了应对深度缓冲和混合混用时产生的问题，要求我们在渲染不能随意决定渲染顺序（更细节部分可以参考LearnOpenGL）。 要想让混合在多个物体上工作，我们需要最先绘制最远的物体，最后绘制最近的物体。这条标准时针对透明物体的，对于非透明物体，只需要保证它们在绘制透明物体之前绘制即可。大体的原则如下： 先绘制所有不透明的物体。 对所有透明的物体排序。 按顺序绘制所有透明的物体。 虽然按照距离排序物体这种方法对我们这个场景能够正常工作，但它并没有考虑旋转、缩放或者其它的变换，奇怪形状的物体需要一个不同的计量，而不是仅仅一个位置向量。完整渲染一个包含不透明和透明物体的场景并不是那么容易。更高级的技术还有**次序无关透明度**(Order Independent Transparency, OIT) 4. 面剔除 对于一个3D立方体而言，我们最多能同时看到的面是3个。这提醒我们在绘制它时可以省略无法看到的面。这能帮助我们提高至少50%的效率（多数情况下我们只能看到2个甚至1个面）。 通过设置三角形顶点的环绕顺序，OpenGL支持我们自由的决定是否剔除面，以及剔除哪些面。面剔除默认是关闭的，开启需要通过glEnable(GL_CULL_FACE)。默认情况下，OpenGL认为从镜头看过去逆时针排布的是正面并且会剔除背面（这种情况下在立方体内部向外看会发现立方体没有被渲染，因为从这个位置向外看时所有面都是顺时针排布）。我们可以通过glCullFace(GLenum mode)决定剔除的是正面，背面或者通通剔除；通过glFrontFace(GLenum mode)决定是以逆时针还是顺时针定义正面。 5. 帧缓冲 到目前为止，我们已经使用了很多屏幕缓冲了：用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存中。OpenGL允许我们定义我们自己的帧缓冲，也就是说我们能够定义我们自己的颜色缓冲，甚至是深度缓冲和模板缓冲。一个完整的帧缓冲需要满足以下的条件： 附加至少一个缓冲（颜色、深度或模板缓冲）。 至少有一个颜色附件(Attachment)。 所有的附件都必须是完整的（保留内存）。 每个缓冲都应该有相同的样本数（sample）。 当完成所有条件后，我们可以使用下面这条命令判断我们的帧缓冲是否完整 if(glCheckFramebufferStatus(GL_FRAMEBUFFER) == GL_FRAMEBUFFER_COMPLETE) // 执行 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:6:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.1 纹理(Texture)附件和渲染缓冲对象(Renderbuffer object)附件 在完整性检查执行之前，我们需要给帧缓冲附加一个附件。附件是一个内存位置，它能够作为帧缓冲的一个缓冲，可以将它想象为一个图像。当创建一个附件的时候我们有两个选项：纹理或渲染缓冲对象。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:7:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.1.1 纹理附件 将纹理附加到帧缓冲区时，所有渲染命令都将写入纹理，就好像它是普通的颜色/深度或模板缓冲区一样。 使用纹理的优势在于，所有渲染操作的结果将会被储存在一个纹理图像中，我们之后可以在着色器中很方便地使用它。 为帧缓冲区创建纹理与创建普通纹理大致相同： unsigned int texture; glGenTextures(1, \u0026texture); glBindTexture(GL_TEXTURE_2D, texture); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 注意到我们将尺寸（width和height）设置为与屏幕一致，且向data参数传递了NULL。同时，我们不关心环绕方式（warping method）和多级渐远纹理（mipmap），因为多数情况我们用不到它们。对于这个纹理，我们仅仅分配了内存而没有填充它。填充这个纹理将会在我们渲染到帧缓冲之后来进行。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:7:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.1.2 渲染缓冲对象附件 渲染缓冲对象(Renderbuffer Object)是在纹理之后引入到OpenGL中，作为一个可用的帧缓冲附件类型。就像纹理图像一样，渲染缓冲对象是一个真正的缓冲，即一系列的字节、整数、像素等。然而，渲染缓冲对象不能被直接读取（它是只写的）。这给它带来了一个额外的优势，那就是OpenGL可以进行一些内存优化，它会将数据储存为OpenGL原生的渲染格式，从而使其在离屏渲染（Off-screen Rendering）到帧缓冲（framebuffer）上的性能优于纹理附件。 渲染缓冲对象直接将所有的渲染数据储存到它的缓冲中，不会做任何针对纹理格式的转换，让它变为一个更快的可写储存介质。因为它的数据已经是原生的格式了，当写入或者复制它的数据到其它缓冲中时是非常快的。所以，交换缓冲这样的操作在使用渲染缓冲对象时会非常快。我们在每个渲染迭代最后使用的glfwSwapBuffers，也可以通过渲染缓冲对象实现：只需要写入一个渲染缓冲图像，并在最后交换到另外一个渲染缓冲就可以了。渲染缓冲对象对这种操作非常完美。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:7:2","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.1.3 对比 渲染缓冲对象能为你的帧缓冲对象提供一些优化，但知道什么时候使用渲染缓冲对象，什么时候使用纹理是很重要的。通常的规则是，如果你不需要从一个缓冲中采样数据，那么对这个缓冲使用渲染缓冲对象会是明智的选择。如果你需要从缓冲中采样颜色或深度值等数据，那么你应该选择纹理附件。性能方面它不会产生非常大的影响的。 [Tips: LearnOpenGL中渲染到纹理章节的代码，实际上做的事是将通常渲染后的画面绘制到自定义的帧缓冲中（不会渲染到屏幕上），并将该画面作为纹理图片保存到纹理附件中。随后再绑定回默认帧缓冲(会渲染到屏幕上)，以之前保存的纹理附件作为纹理渲染画面，使得整个场景都被渲染到了一个纹理上] ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:7:3","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.2 后期处理 既然整个场景都被渲染到了一个纹理上，我们可以简单地通过修改纹理数据创建出一些非常有意思的效果。LearnOpenGL提到的后期处理包括反相（对所有颜色取1-color的操作），灰度（移除场景中除了黑白灰以外所有的颜色），以及核效果（在当前纹理坐标的周围取一小块区域，对当前纹理值周围的多个纹理值进行采样，创建一些意思的效果，比如模糊、边缘检测）等。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:8:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"5.3 代码样例 // 创建帧缓冲 // ------------ unsigned int framebuffer; glGenFramebuffers(1, \u0026framebuffer); glBindFramebuffer(GL_FRAMEBUFFER, framebuffer); // 生成纹理 unsigned int texColorBuffer; glGenTextures(1, \u0026texColorBuffer); glBindTexture(GL_TEXTURE_2D, texColorBuffer); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0); // 将它附加到当前绑定的帧缓冲对象 // 创建渲染缓冲对象 unsigned int rbo; glGenRenderbuffers(1, \u0026rbo); glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, SCR_WIDTH, SCR_HEIGHT); glBindRenderbuffer(GL_RENDERBUFFER, 0); glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); // 检查帧缓冲是否完整 if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) std::cout \u003c\u003c \"ERROR::FRAMEBUFFER:: Framebuffer is not complete!\" \u003c\u003c std::endl; glBindFramebuffer(GL_FRAMEBUFFER, 0); while(!glfwWindowShouldClose(window)){ /*渲染前处理*/ // 开始渲染 // ------ // 绑定到帧缓冲区并绘制场景，就像通常情况下为纹理上色一样（此时绘制的场景不会显示到屏幕上） glBindFramebuffer(GL_FRAMEBUFFER, framebuffer); glEnable(GL_DEPTH_TEST); // enable depth testing (is disabled for rendering screen-space quad) /*将场景渲染到帧缓冲中*/ // 现在绑定回默认帧缓冲区，并使用附加的帧缓冲区颜色纹理绘制一个四边形平面 glBindFramebuffer(GL_FRAMEBUFFER, 0); glDisable(GL_DEPTH_TEST); // 关闭深度测试确保screen-space不会因为深度测试被舍弃 glClearColor(1.0f, 1.0f, 1.0f, 1.0f); // 清理屏幕 glClear(GL_COLOR_BUFFER_BIT); screenShader.use(); glBindVertexArray(quadVAO); // quadVAO通常是一个屏幕大小的四边形，包含三个点 glBindTexture(GL_TEXTURE_2D, texColorBuffer); // 使用颜色附加纹理作为纹理的四面 glDrawArrays(GL_TRIANGLES, 0, 6); /*检查并调用事件，交换缓冲*/ } 6. 立方体贴图 简而言之，立方体贴图就是一个包含了6个2D纹理的纹理，每个2D纹理都组成了立方体的一个面：一个有纹理的立方体。使用立方体贴图的原因是它有一个非常有用的特性，它可以通过一个方向向量来进行索引/采样。假设我们有一个1x1x1的单位立方体，方向向量的原点位于它的中心。使用一个橘黄色的方向向量来从立方体贴图上采样一个纹理值会像是这样： ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:9:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"6.1 天空盒 立方体贴图一个比较常见的用途是用来渲染场景四周的天空盒，它的纹理加载与普通2D的纹理加载需要注意对R轴的配置： // 立方体贴图要考虑三维情况 glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE); 对于天空盒的渲染，不需要使用model矩阵，同时对于view矩阵也需要调整（view矩阵的旋转、缩放和位移都会改变天空盒的所有位置），我们可以用下面的代码让天空盒保持不变： // 取4x4矩阵左上角的3x3矩阵来移除变换矩阵的位移部分 glm::mat4 view = glm::mat4(glm::mat3(camera.GetViewMatrix())); 为了让代码更加高效，我们选择最后渲染天空盒，因为天空盒默认总是在场景中最远处的位置，最后对它进行渲染可以减少我们调用着色器进行渲染的次数。然而天空盒只是一个1x1x1的立方体，这意味着它很难通过大部分深度测试。我们可以通过以下代码让天空盒的深度值z总是为1.0： void main() { TexCoords = aPos; vec4 pos = projection * view * vec4(aPos, 1.0); // 透视除法会在顶点着色器运行之后执行，将gl_Position的xyz坐标除以w分量。 // 通过将z值设位w，保证了天空盒的深度值总为1.0 gl_Position = pos.xyww; } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:10:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"6.2 环境映射 我们现在将整个环境映射到了一个纹理对象上了，能利用这个信息的不仅仅只有天空盒。通过使用环境的立方体贴图，我们可以给物体反射和折射的属性。这样使用环境立方体贴图的技术叫做环境映射(Environment Mapping)，其中最流行的两个是反射(Reflection)和折射(Refraction)。 其中反射的原理与光照中的高光十分相似，通过着色位置到摄像机的向量和着色处的法线，我们可以利用GLSL内建的reflect函数获取反射向量。然后利用立方体贴图的特性，获取该着色片段的纹理。 void main() { vec3 I = normalize(Position - cameraPos); // 入射向量 vec3 R = reflect(I, normalize(Normal)); // 反射向量 FragColor = vec4(texture(skybox, R).rgb, 1.0); } 折射的思想与反射类似，都是通过入射视角和法线关系获取折射向量。与反射一样，利用GLSL内建的refract函数，以及折射率可以很容易获取折射向量。（教程里涉及的是单面折射，多面折射需要更加精确的物理分析） void main() { float ratio = 1.00 / 1.52; // 从空气进入玻璃的折射率 vec3 I = normalize(Position - cameraPos); // 入射向量 vec3 R = refract(I, normalize(Normal), ratio); // 折射向量 FragColor = vec4(texture(skybox, R).rgb, 1.0); } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:11:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"6.3 动态环境贴图 上面提到的环境映射是静态环境映射，这存在问题：例如，对于一面可以反射的镜子而言，它能反射的只有四周的环境。这当然不合理，因为它应该优先反射离自己最近的物体。 我们可以利用之前的帧缓冲为物体的6个不同角度创建出场景的纹理，并在每个渲染迭代中将它们储存到一个立方体贴图中。之后我们就可以使用这个（动态生成的）立方体贴图来创建出更真实的，包含其它物体的，反射和折射表面了。这就叫做动态环境映射(Dynamic Environment Mapping) 动态环境贴图的主要麻烦是：非常大的性能开销，因为我们需要为使用环境贴图的物体渲染场景6次！现代程序通常会尽可能使用天空盒，并在可能的时候使用预编译的立方体贴图，只要它们能产生一点动态环境贴图的效果。虽然动态环境贴图是一个很棒的技术，但是要想在不降低性能的情况下让它工作还是需要非常多的技巧（研究点）。 7. 高级数据 目前为止，我们一直使用glBufferData函数来填充缓冲对象所管理的内存，这个函数会分配一块内存，并将数据添加到这块内存中。如果我们将它的data参数设置为NULL，那么这个函数将只分配内存但不进行填充。在我们需要预留(Reserve)特定大小的内存，之后回到这个缓冲一点一点填充的时候会很有用。 除了使用一次函数调用填充整个缓冲之外，我们可以使用glBufferSubData，填充缓冲的特定区域。 // 注意在此之前先用glBufferData预留足够大的空间 glBufferSubData(GL_ARRAY_BUFFER, 24, sizeof(data), \u0026data); // 范围： [24, 24 + sizeof(data)] 将数据导入缓冲的另外一种方法是，请求缓冲内存的指针，直接将数据复制到缓冲当中： float data[] = {...}; glBindBuffer(GL_ARRAY_BUFFER, buffer); // 通过调用glMapBuffer函数，OpenGL会返回当前绑定缓冲的内存指针，供我们操作： void *ptr = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY); // 复制数据到内存 memcpy(ptr, data, sizeof(data)); // 记得告诉OpenGL我们不再需要这个指针了 glUnmapBuffer(GL_ARRAY_BUFFER); 如果要直接映射数据到缓冲，而不事先将其存储到临时内存中，glMapBuffer这个函数会很有用。比如说，你可以从文件中读取数据，并直接将它们复制到缓冲内存中。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:12:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"7.2 分批顶点属性 之前我们对顶点缓冲采取的都是交错(Interleave)处理，即将每一个顶点的位置、发现和/或纹理坐标紧密放置在一起。利用glBufferSubData，我们可以采用分批(Batched)的方式： float positions[] = { ... }; float normals[] = { ... }; float tex[] = { ... }; /*生成并绑定缓冲对象*/ // 填充缓冲，以下代码省略了glEnableVertexAttribArray() glBufferData(GL_ARRAY_BUFFER, sizeof(positions) + sizeof(normals) + sizeof(tex), nullptr, GL_STATIC_DRAW); // 别忘了先为缓冲分配足够内存 glBufferSubData(GL_ARRAY_BUFFER, 0, sizeof(positions), \u0026positions); glBufferSubData(GL_ARRAY_BUFFER, sizeof(positions), sizeof(normals), \u0026normals); glBufferSubData(GL_ARRAY_BUFFER, sizeof(positions) + sizeof(normals), sizeof(tex), \u0026tex); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), 0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)(sizeof(positions))); glVertexAttribPointer( 2, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(float), (void*)(sizeof(positions) + sizeof(normals))); ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:13:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"7.2 复制缓冲 glCopyBufferSubData能够让我们从一个缓冲中复制数据到另一个缓冲中 void glCopyBufferSubData(GLenum readtarget, GLenum writetarget, GLintptr readoffset, GLintptr writeoffset, GLsizeiptr size); // readtarget和writetarget参数需要填入复制源和复制目标的缓冲目标 // glCopyBufferSubData会从readtarget中读取size大小的数据，并将其写入writetarget缓冲的writeoffset偏移量处 我们可以将GL_ARRAY_BUFFER缓冲复制到GL_ELEMENT_ARRAY_BUFFER缓冲，但当源和目标都是顶点数组缓冲时，OpenGL提供了额外的两个缓冲目标，叫做GL_COPY_READ_BUFFER和GL_COPY_WRITE_BUFFER。 float vertexData[] = { ... }; glBindBuffer(GL_COPY_READ_BUFFER, vbo1); // 或者 glBindBuffer(GL_ARRAY_BUFFER, vbo1); glBindBuffer(GL_COPY_WRITE_BUFFER, vbo2); glCopyBufferSubData(GL_COPY_READ_BUFFER, GL_COPY_WRITE_BUFFER, 0, 0, sizeof(vertexData)); // 或者 glCopyBufferSubData(GL_ARRAY_BUFFER, GL_COPY_WRITE_BUFFER, 0, 0, sizeof(vertexData)); 8. 高级GLSL 本章主要介绍有一些用的内建变量(Built-in Variable)，管理着色器输入和输出的新方式以及一个叫做Uniform缓冲对象(Uniform Buffer Object)的有用工具。了解这些可以让编程更加轻松。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:14:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.1 GLSL的内建变量 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:15:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.1.2 顶点着色器变量 gl_PointSize GLSL定义了一个叫做gl_PointSize的输出变量，它是一个float变量，我们可以使用它来设置点的宽高（像素）。在顶点着色器中修改点的大小的话，你就能对每个顶点设置不同的值了。 在顶点着色器中修改点大小的功能默认是禁用的，如果需要启用它的话，需要启用OpenGL的 glEnable(GL_PROGRAM_POINT_SIZE); 下面的例子重新设置了顶点的像素，使得点的大小会随着观察者距顶点距离变远而增大。 void main() { gl_Position = projection * view * model * vec4(aPos, 1.0); gl_PointSize = gl_Position.z; } 对每个顶点使用不同的点大小，会在粒子生成之类的技术中很有意思 gl_VertexID GLSL还定义了一个有趣的输入变量，我们只能对它进行读取，叫做gl_VertexID。它是一个整型变量，储存了正在绘制顶点的当前ID。当（使用glDrawElements）进行索引渲染的时候，这个变量会存储正在绘制顶点的当前索引。当（使用glDrawArrays）不使用索引进行绘制的时候，这个变量会储存从渲染调用开始的已处理顶点数量。（通常情况我们不会用到它，但知道该信息是可读的总是好的） ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:15:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.1.2 片段着色器 gl_FragCoord gl_FragCoord是一个vec4的只读的输入变量，其四个分量分别对应x, y, z和1/w。它的x和y分量是片段的窗口空间(Window-space)坐标，其原点为窗口的左下角。x, y是浮点数，且小数部分恒为0.5。x - 0.5和y - 0.5分别位于[0, windowWidth - 1]和[0, windowHeight - 1]内 // 我们首先glViewport()设定了一个800x600的窗口 // 以下代码实现了通过x分割屏幕渲染颜色的效果 void main() { if(gl_FragCoord.x \u003c 400) FragColor = vec4(1.0, 0.0, 0.0, 1.0); else FragColor = vec4(0.0, 1.0, 0.0, 1.0); } gl_FragCoord的一个常见用处是用于对比不同片段计算的视觉输出效果，这在技术演示中可以经常看到。 gl_FrontFacing gl_FrontFacing是一个bool型的输入变量。如果我们不（启用GL_FACE_CULL来）使用面剔除，它会告诉我们当前片段是属于正向面的一部分还是背向面的一部分。（面剔除章节所提到的根据顶点定义的顺/逆时针来决定是正面还是反面） // frontTexture, backTexture都是预定定义的uniform的纹理变量 void main( { if(gl_FrontFacing) // 若为True，则为正面 FragColor = texture(frontTexture, TexCoords); else FragColor = texture(backTexture, TexCoords); } gl_FragDepth GLSL提供给我们一个叫做gl_FragDepth的输出变量，我们可以使用它来在着色器内设置片段的深度值。 // 想要写入深度值，直接将写入一个[0.0, 1.0]的数即可 gl_FragDepth = 0.0; 不过修改深度值意味着我们不能进行提前深度测试(Early Depth Testing)，因为深度值可变意味着OpenGL无法在着色器运行前确定片段的深度值。 不过，从OpenGL 4.2起，我们仍可以对两者进行一定的调和，在片段着色器的顶部使用深度条件(Depth Condition)重新声明gl_FragDepth变量： layout (depth_condition) out float gl_FragDepth; // condition可以为下面的值： // any 默认值。提前深度测试是禁用的，你会损失很多性能 // greater 你只能让深度值比gl_FragCoord.z更大 // less 你只能让深度值比gl_FragCoord.z更小 // unchanged 如果你要写入gl_FragDepth，你将只能写入gl_FragCoord.z的值 这样，当深度值比片段的深度值要小的时候，OpenGL仍是能够进行提前深度测试的。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:15:2","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.1.3 接口块 GLSL为我们提供了接口块(Interface Block)，便于我们以数组或结构体的形式从顶点着色器向片段着色器之间传递变量。 接口块的声明和struct的声明有点相像，不同的是，现在根据它是一个输入还是输出块(Block)，使用in或out关键字来定义的。 // 定义于顶点着色器 out VS_OUT { vec2 TexCoords; } vs_out; // vs_out是该结构体的一个实体 // 定义于片段着色器 in VS_OUT // 块名要与顶点着色器保持一致 { vec2 TexCoords; } fs_in; // fs_in是该结构体的一个实体，它的命名没有规定，但应避免使用误导性名称 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:15:3","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.2 Uniform缓冲对象 此前在设置uniform变量时，我们面临的一个问题是：当使用多于一个的着色器时，尽管大部分的uniform变量都是相同的，我们还是需要不断地设置它们。 OpenGL为我们提供了一个叫做Uniform缓冲对象(Uniform Buffer Object)的工具，它允许我们定义一系列在多个着色器中相同的全局Uniform变量。当使用Uniform缓冲对象时，我们只需要设置相关的uniform一次。 Uniform缓冲对象是一个缓冲对象，故我们可以使用glGenBuffers来创建它，将它绑定到GL_UNIFORM_BUFFER缓冲目标，并将所有相关的uniform数据存入缓冲。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:16:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.2.1 Uniform块布局 在Uniform缓冲对象中储存数据是有一些规则的。默认情况下，GLSL会使用一个叫做共享(Shared)布局的Uniform内存布局，共享是因为一旦硬件定义了偏移量，它们在多个程序中是共享并一致的（OpenGL没有声明内存块中变量间的间距(Spacing)，这允许硬件能够在它认为合适的位置放置变量）。使用共享布局，GLSL是可以为了优化而对uniform变量的位置进行变动的，只要变量的顺序保持不变。这带来的问题是，我们无法清楚的知道每个uniform变量的偏移量，以至于我们不知道如何准确填充Uniform缓冲（尽管OpenGL提供了glGetUniformIndices查询这个信息，但这并不直观）。 为了能够准确且更加容易地填充Uniform缓冲对象，我们将Uniform的块布局方式显示的设置为std140。 std140是一种内存布局方式，在这种内存布局方式下，Uniform块中的每个变量都有一个基准对齐量(Base Alignment)，它等于一个变量在Uniform块中所占据的空间（包括填充量(Padding)），这个基准对齐量是使用std140布局的规则计算出来的。接下来，对每个变量，我们再计算它的对齐偏移量(Aligned Offset)，它是一个变量从块起始位置的字节偏移量。一个变量的对齐字节偏移量必须等于基准对齐量的倍数。 /* 常见的对其规则 类型 布局规则 标量，比如int和bool 每个标量的基准对齐量为N。 向量 2N或者4N。这意味着vec3的基准对齐量为4N。 标量或向量的数组 每个元素的基准对齐量与vec4的相同。 矩阵 储存为列向量的数组，每个向量的基准对齐量与vec4的相同。 结构体 等于所有元素根据规则计算后的大小，但会填充到vec4大小的倍数。 */ // Uniform内存块计算示例（单位是byte） layout (std140) uniform ExampleBlock { // 基准对齐量 // 对齐偏移量 float value; // 4 // 0 vec3 vector; // 16 // 16 (必须是16的倍数，所以 4-\u003e16) mat4 matrix; // 16 // 32 (列 0) // 16 // 48 (列 1) // 16 // 64 (列 2) // 16 // 80 (列 3) float values[3]; // 16 // 96 (values[0]) // 16 // 112 (values[1]) // 16 // 128 (values[2]) bool boolean; // 4 // 144 int integer; // 4 // 148 }; 虽然std140布局不是最高效的布局，但它保证了内存布局在每个声明了这个Uniform块的程序中是一致的。 除了shader和std140布局外，还有有一种名为packed的布局。它不能保证这个布局在每个程序中保持不变，因为它允许编译器去将uniform变量从Uniform块中优化掉，这在每个着色器中都可能是不同的。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:16:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.2.2 使用Uniform缓冲 为了知道Uniform缓冲和Uniform块的对应关系，在OpenGL上下文中，定义了一些绑定点(Binding Point)，我们可以将一个Uniform缓冲链接至它。在创建Uniform缓冲之后，我们将它绑定到其中一个绑定点上，并将着色器中的Uniform块绑定到相同的绑定点，把它们连接到一起。过程如下图所示： 我们可以调用glGetUniformBlockIndex和glUniformBlockBinding实现绑定，例如对于上图中的Light Uniform模块，我们可以采用下面的方式对其绑定： unsigned int lights_index = glGetUniformBlockIndex(shaderA.ID, \"Lights\"); glUniformBlockBinding(shaderA.ID, lights_index, 2); 从OpenGL 4.2版本起，我们也可以添加一个布局标识符，显式地将Uniform块的绑定点储存在着色器中，这样就不用再调用glGetUniformBlockIndex和glUniformBlockBinding了。下面的代码显式地设置了Lights Uniform块的绑定点。 layout(std140, binding = 2) uniform Lights { ... }; ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:16:2","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"8.3.3 设置Uniform缓冲 现在，我们已经知道了Uniform缓冲的原理，是时候总结如何设置Uniform缓冲了。 对于着色器，我们以结构体的形式创建Uniform块： layout (std140) uniform Matrices { mat4 projection; mat4 view; }; 我们在程序中创建Uniform缓冲，并将其绑定到正确的位置： // 配置uniform缓冲对象 // --------------------------------- // 首先，获取相关的区块索引 unsigned int uniformBlockIndexRed = glGetUniformBlockIndex(shaderRed.ID, \"Matrices\"); unsigned int uniformBlockIndexGreen = glGetUniformBlockIndex(shaderGreen.ID, \"Matrices\"); // 然后我们将每个着色器的统一块链接到这个统一绑定点（将Matrices Uniform块链接到绑定点0） glUniformBlockBinding(shaderRed.ID, uniformBlockIndexRed, 0); glUniformBlockBinding(shaderGreen.ID, uniformBlockIndexGreen, 0); // 现在，创建缓冲区 unsigned int uboMatrices; glGenBuffers(1, \u0026uboMatrices); glBindBuffer(GL_UNIFORM_BUFFER, uboMatrices); glBufferData(GL_UNIFORM_BUFFER, 2 * sizeof(glm::mat4), NULL, GL_STATIC_DRAW); glBindBuffer(GL_UNIFORM_BUFFER, 0); // 定义链接到统一绑定点的缓冲区的范围 glBindBufferRange(GL_UNIFORM_BUFFER, 0, uboMatrices, 0, 2 * sizeof(glm::mat4)); // 存储投影矩阵（仅执行一次）（注意：这里不再通过更改FoV来使用缩放） glm::mat4 projection = glm::perspective(45.0f, (float)SCR_WIDTH / (float)SCR_HEIGHT, 0.1f, 100.0f); glBindBuffer(GL_UNIFORM_BUFFER, uboMatrices); glBufferSubData(GL_UNIFORM_BUFFER, 0, sizeof(glm::mat4), glm::value_ptr(projection)); glBindBuffer(GL_UNIFORM_BUFFER, 0); // 渲染循环 // ------- while{ ... // 渲染 // ---- // 在统一块中设置视图矩阵（我们每个循环迭代只需执行一次） glm::mat4 view = camera.GetViewMatrix(); glBindBuffer(GL_UNIFORM_BUFFER, uboMatrices); glBufferSubData(GL_UNIFORM_BUFFER, sizeof(glm::mat4), sizeof(glm::mat4), glm::value_ptr(view)); glBindBuffer(GL_UNIFORM_BUFFER, 0); /*绘图*/ ... } 9. 几何着色器 在顶点和片段着色器之间有一个可选的几何着色器(Geometry Shader)，它的输入是一个图元（如点或三角形）的一组顶点。几何着色器可以在顶点发送到下一着色器阶段之前对它们随意变换。然而，几何着色器最有趣的地方在于，它能够将（这一组）顶点变换为完全不同的图元，并且还能生成比原来更多的顶点。 下面例子中，我们首先声明了几何着色输入/输出图元类型，图元值的具体类型可以参照LearnOpenGL。 #version 330 core layout (points) in; // 声明从顶点着色器输入的图元类型 layout (line_strip, max_vertices = 2) out; // 前者指定几何着色器输出的图元类型。后者指定了它最大能够输出的顶点数量（超过该数量的点不会被绘制） // 这个例子中，我们发射了两个顶点，它们从原始顶点位置平移了一段距离，之后调用了EndPrimitive，将这两个顶点合成为一个包含两个顶点的线条。 void main() { gl_Position = gl_in[0].gl_Position + vec4(-0.1, 0.0, 0.0, 0.0); EmitVertex(); // 使gl_Position中的向量被添加到图元中 gl_Position = gl_in[0].gl_Position + vec4( 0.1, 0.0, 0.0, 0.0); EmitVertex(); // 使所有发射出的(Emitted)顶点都会合成为指定的输出渲染图元 EndPrimitive(); } GLSL提供给我们一个内建(Built-in)变量gl_in[]帮助我们生成更有意义的结果： in gl_Vertex // 它被声明为一个接口块 { vec4 gl_Position; float gl_PointSize; float gl_ClipDistance[]; } gl_in[]; // 要注意的是，它被声明为一个数组，因为大多数的渲染图元包含多于1个的顶点 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:16:3","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"9.1 爆破物体 几何着色器可以支持我们实现爆破效果，所谓的爆破，指的是将每个三角形沿着法向量的方向移动一小段时间。其效果是，整个物体看起来像是沿着每个三角形的法线向量爆炸一样。这样的几何着色器效果的一个好处就是，无论物体有多复杂，它都能够应用上去。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:17:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"9.2 法向量可视化 几何着色器的一个很大的作用是：显示任意物体的法向量。当编写光照着色器时，你可能会最终会得到一些奇怪的视觉输出，但又很难确定导致问题的原因。光照错误很常见的原因就是法向量错误，这可能是由于不正确加载顶点数据、错误地将它们定义为顶点属性或在着色器中不正确地管理所导致的。我们想要的是使用某种方式来检测提供的法向量是正确的。检测法向量是否正确的一个很好的方式就是对它们进行可视化，几何着色器正是实现这一目的非常有用的工具。 其思路是：首先在没有几何体着色器的情况下正常绘制场景，然后再次绘制场景，但是这次仅显示通过几何体着色器生成的法向矢量。几何着色器将三角形图元作为输入，并从它们的法线方向生成3条线——每个顶点一个法线向量。 // 法向量可视化 shader.use(); DrawScene(); normalDisplayShader.use(); DrawScene(); 10. 实例化（Instancing） 想像一下我们有成千上万个相同的、简单的模型，它们的顶点排布一样，贴图纹理一样，区别只是在场景的位置和自身的伸缩、旋转情况。若按照我们此前一直在用的方式进行渲染，那我们很快就会遭遇性能瓶颈，因为这个过程调用了太多次的draw。与渲染实际的顶点相比，告诉GPU渲染你的顶点数据使用像gldrawarray或glDrawElements这样的函数消耗了相当多的性能，因为OpenGL必须在绘制你的顶点数据之前做必要的准备(比如告诉GPU从哪个缓冲区读取数据，在哪里找到顶点属性以及所有这些相对较慢的CPU到GPU总线)。 这种情况下，我们需要用到实例化（instancing）技术，它可以通过一个渲染调用在一次绘制许多（相等网格数据）对象，从而在每次需要渲染对象时为我们节省了所有CPU-\u003e GPU通信。要使用实例化进行渲染，需要用到glDrawArraysInstanced或者glDrawElementsInstanced函数。它们带有一个额外的参数—— instance count，来设置我们要渲染的实例数。不过仅此而已还不够，因为绘制出的画面会重叠，为了实现实例化，我们还需要定义每个待渲染物体的 为此，我们需要用到一个GLSL的内建变量gl_InstanceID，它代表着每个待渲染物体的ID，下标从0开始。我们只需要在顶点着色器中（以数组形式）定义多个uniform变量，为每个实例做不同的转换，就能渲染出非重叠的图像了。 // 定义顶点着色器 #version 330 core layout (location = 0) in vec2 aPos; ... uniform vec2 offsets[100]; void main() { gl_Position = vec4(aPos + offsets[gl_InstanceID], 0.0, 1.0); ... } // 渲染100个相同的实体，它们在空间中位置不同 shader.use(); for(unsigned int i = 0; i \u003c 100; i++) { shader.setVec2((\"offsets[\" + std::to_string(i) + \"]\")), translations[i]); // tanslations是一个vector\u003cvec2\u003e的数组 } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:18:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"10.1 实例数组（Instanced arrays） 尽管先前的实现在此特定用例下效果很好，但是每当渲染100个以上的实例（这是很常见的）时，我们最终都会达到可发送到着色器的统一数据量的限制（每个着色器阶段都有可用uniform的数量限制）。 一种替代选择是实例数组。 实例数被组定义为一个顶点属性（允许我们存储更多数据），它是按实例而不是按顶点更新的。 // 将实例数组定义为顶点属性 unsigned int instanceVBO; glGenBuffers(1, \u0026instanceVBO); glBindBuffer(GL_ARRAY_BUFFER, instanceVBO); glBufferData(GL_ARRAY_BUFFER, sizeof(glm::vec2) * 100, \u0026translations[0], GL_STATIC_DRAW); glBindBuffer(GL_ARRAY_BUFFER, 0); glEnableVertexAttribArray(2); glBindBuffer(GL_ARRAY_BUFFER, instanceVBO); glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(float), (void*)0); glBindBuffer(GL_ARRAY_BUFFER, 0); glVertexAttribDivisor(2, 1); // 通过将此属性设置为1，我们告诉OpenGL我们想在开始渲染新实例时更新顶点属性的内容。 // glVertexAttribDivisor函数告诉OpenGL何时将顶点属性的内容更新到下一个元素。它的第一个参数是所讨论的顶点属性，第二个参数是属性除数。 // 顶点着色器 #version 330 core layout (location = 0) in vec2 aPos; layout (location = 1) in vec3 aColor; layout (location = 2) in vec2 aOffset; out vec3 fColor; void main() { gl_Position = vec4(aPos + aOffset, 0.0, 1.0); fColor = aColor; } 11. 反走样（Anti Aliasing） 渲染画面的物体边缘处有时会出现许多锯齿，尤其是在放大物体时，锯齿会更加明显。这种现象被称之为走样，它产生的本质是因为场景定义在三维空间中式连续的，而最终显示的却是一个二维离散的数组。所以判断一个点到底没有被某个像素覆盖的时候单纯是一个“有”或“没有\"问题，丢失了连续性信息，从而产生锯齿。（之所以物体边缘容易产生锯齿是因为物体边缘处通常伴随着频域的极速变化） 显然，走样的产生与分辨率有关，所以一个很自然的反走样手段是超采样抗锯齿(Super Sample Anti-aliasing, SSAA)，它会使用比正常分辨率更高的分辨率（即超采样）来渲染场景，当图像输出在帧缓冲中更新时，分辨率会被下采样(Downsample)至正常的分辨率。不过这种方式的开销太大，如今已鲜有人问津。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:19:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"11.1 多重采样 多重采样抗锯齿(Multisample Anti-aliasing, MSAA)是目前一种更聪明的技术，因为它只在光栅化阶段（光栅化：光栅器接受三维空间中顶点作为输入，经过光栅化后将其转换为二维屏幕上的一个片段）判断像素是否被三角形覆盖。多重采样实际做的就是在一个像素中放置多个采样点（自定义采样点的排布），通过判断有多少个采样点落在三角形内部，我们可以对最后的着色做平滑处理。 上图展示了放置单一采样点和多个采样点的区别，对于前者我们对像素的处理只有“是”或“不是”；而对于后者我们增加了一些平滑处理，实际的着色情况可以表示为$color=textrue*0.5$。 // GLFW负责创建多重采样缓冲 glfwWindowHint(GLFW_SAMPLES, 4); // 设置采样点 ... glEnable(GL_MULTISAMPLE); // 开启多重采样 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:20:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"11.2 离屏MSAA 除了上述所说的由GLFW创建多重采样缓冲，我们也可以使用自己定义的帧缓冲来实现离屏渲染。 有两种方式可以创建多重采样缓冲，将其作为帧缓冲的附件：纹理附件和渲染缓冲附件。这和在帧缓冲教程中所讨论的普通附件很相似。这里有一个完整示例。与普通的离屏渲染相比，离屏MSAA需要声明多重采样： // 注意区分glTexImage2D // 它的第二个参数设置的是纹理所拥有的样本个数。 // 最后一个参数设置为GL_TRUE，表明图像将会对每个纹素使用相同的样本位置以及相同数量的子采样点个数。 glTexImage2DMultisample(GL_TEXTURE_2D_MULTISAMPLE, 4, GL_RGB, width, height, GL_TRUE); // 注意到第三个参数被设置为了GL_TEXTURE_2D_MULTISAMPLE，表示多重采样 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D_MULTISAMPLE, tex, 0); // 注意区分glRenderbufferStorage glRenderbufferStorageMultisample(GL_RENDERBUFFER, 4, GL_DEPTH24_STENCIL8, width, height); 需要注意的是多重采样缓冲有一点特别，我们不能直接将它们的缓冲图像用于其他运算，比如在着色器中对它们进行采样。一个多重采样的图像包含比普通图像更多的信息，我们所要做的是缩小或者还原(Resolve)图像。调用glBlitFramebuffer可以将一个帧缓冲中的某个区域复制到另一个帧缓冲中，并且将多重采样缓冲还原。多重采样离屏渲染流程： 多重采样帧缓冲绘制图形 拷贝多重采样纹理到普通帧缓冲中的纹理对象里 绘制普通帧缓冲中的纹理对象到默认帧（当前屏幕）缓冲 如果我们想对多重采样缓冲渲染的图像做后期处理，那我们需要先将其复制到一个没有使用多重采样纹理附件的中介缓冲对象中，然后用这个普通的颜色附件来做后期处理。因为我们不能直接在片段着色器中使用多重采样纹理。（不过这意味着可能会重新出现锯齿，因为屏幕纹理又变回了一个只有单一采样点的普通纹理。我们可以进行模糊处理或者创造自己的抗锯齿算法） glBindFramebuffer(GL_READ_FRAMEBUFFER, multisampledFBO); // 将多重采样绑定到只读缓冲中 glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0); // 将默认缓冲绑定到只写缓冲中，意味着渲染的画面会出现在屏幕上 // glBindFramebuffer(GL_DRAW_FRAMEBUFFER, intermediateFBO); // 若要做后期处理，则把一个普通的缓冲绑定到只写缓冲中 glBlitFramebuffer(0, 0, width, height, 0, 0, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST); ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:21:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"11.3 自定义抗锯齿算法 将一个多重采样的纹理图像不进行还原直接传入着色器也是可行的。GLSL为我们提供了对纹理图像的每个子样本采样的选项，因此我们可以创建自己的抗锯齿算法（在大型的图形应用中通常都会这么做）。 // 为了获取每个子样本的颜色值，需要将纹理uniform采样器设置为sampler2DMS uniform sampler2DMS screenTextureMS; // 使用texelFetch函数能够获取每个子样本的颜色值 vec4 colorSample = texelFetch(screenTextureMS, TexCoords, 3); ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/:22:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——高级OpenGL","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%AB%98%E7%BA%A7opengl/"},{"categories":["OpenGL学习笔记"],"content":"1. 颜色 图形学中物体所呈现的颜色可以理解为光照射到该物体上后，该物体所反射出来的颜色，即物体从一个光源反射各个颜色分量的大小。 // 光的颜色*物体颜色 = 物体反射处的颜色 glm::vec3 lightColor(0.33f, 0.42f, 0.18f); glm::vec3 toyColor(1.0f, 0.5f, 0.31f); glm::vec3 result = lightColor * toyColor; // = (0.33f, 0.21f, 0.06f); 2. 基础光照 最经典的（基础的）光照模型是Bllin-Phong光照模型，该模型定义了环境光(ambient), 漫反射(diffuse)和高光(specular)，它们共同作用于物体来为物体着色。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:0:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"2.1 环境光 环境光由我们自己定义 // 环境光 float ambientStrength = 0.1; vec3 ambient = ambientStrength * lightColor; ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:1:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"2.2 漫反射 漫反射的计算需要知道物体表面的法向量（垂直于片段表面的一个向量，我们只需要定义三角形顶点的法向量，任一片段表面的法向量可以由插值计算得出），以及定义的光线。为了得到余弦值$cos\\theta$，需要保证光线和法线都是单位向量，故需要注意对向量进行标准化。 $$L_d =k_d(I/r^2)max(0,n·I)$$ 上式将光视作强度（实际上这种说法并不符合物理学定义，因为很难给光的强度赋予实际的物理意义。由物理意义的光源需要借助辐射度量学的知识），其中$k_d$代表漫反射系数，即物体材质颜色。$I/r^2$表示光的强度随距离而衰减。然而，若$I$是类似于太阳的存在，则可以近似的忽略光线强度衰减。我们通常将平行于场景的平行光定义为类似于太阳的不会发生衰减的光，而对于点光源则认为它会随着距离逐渐衰减。（后续代码中点光源没有考虑衰减只是为了便于学习） ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:2:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"2.2.1 法线转换为世界坐标系 考虑到片段着色器中的计算都是在世界坐标系中进行的，相应的，法线也应该转换为世界坐标系。不过这不能简单的乘以转换矩阵。 首先，法向量只是一个方向向量，不能表达空间中的特定位置。因此，如果我们打算把法向量乘以一个模型矩阵，我们就要从矩阵中移除位移部分，只选用模型矩阵左上角3×3的矩阵（可以把法向量的$w$分量设置为0，再乘以4×4矩阵）。对于法向量，我们只希望对它实施缩放和旋转变换。然而不等比缩放会导致法线不再垂直于片元表面，可以通过法线矩阵来修正这个错误，其定义为「模型矩阵左上角的逆矩阵的转置矩阵」。 Normal = mat3(transpose(inverse(model))) * aNormal; （注意：对于着色器而言，逆矩阵是一种开销较大的计算。这里选择在着色器中计算是出于学习原因。在实际的工程中，在绘制之前最好用CPU计算出法线矩阵，然后通过uniform把值传递给着色器（像模型矩阵一样）） ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:2:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"2.3 镜面反射 镜面反射的结果受观察者（摄像机）影响，通过计算光线经过法线的反射向量与观察者向量之间的夹角，可以得出镜面反射的强度。考虑到这个强度通常较小区分不太明显，因此需要对夹角添加一个$p$次方（加大差异性）。$p$被称作反光度（shininess），其值越大，反光能力越强，散射越小，高光点就会越小。 OpenGL内置的反射函数可以帮助我们轻松获得反射向量（冯模型，一个明显的问题是视角和反射光线的夹角可能大于90°导致高光为零）。我们也可以不计算反射向量，利用$normalize(I + v)$求半程向量$h$，通过$h·n$近似获得反射向量与观察者向量间的夹角（Blinn-Phong模型，避免了之前所说的高光为零的情况。对于反光度很小的物体，Blinn-Phong着色的渲染效果更加真实）。 $$L_s=k_s(I/r^2)max(cos\\alpha, 0)=k_s(I/r^2)max(h·n,0)$$ ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:3:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"2.4 基于BIIion-Phong模型的片元着色器 #version 330 core out vec4 FragColor; uniform vec3 lightPos; uniform vec3 objectColor; uniform vec3 lightColor; uniform vec3 viewPos; in vec3 FragPos; in vec3 Normal; void main() { // 环境光 float ambientStrength = 0.1; vec3 ambient = ambientStrength * lightColor; // 漫反射 vec3 norm = normalize(Normal); vec3 lightDir = normalize(lightPos - FragPos); float diff = max(dot(norm, lightDir), 0.0); vec3 diffuse = diff * lightColor; // 镜面光照 float specularStrength = 0.8; vec3 viewDir = normalize(viewPos - FragPos); vec3 reflectDir = reflect(-lightDir, norm); // reflect()要求向量的方向从片元指向光源，这与lightDir正相反 float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32); // 32是反光度，反光度越高，反射光的能力越强，散射得越少，高光点就会越小 vec3 specular = specularStrength * spec * lightColor; vec3 result = (ambient + diffuse + specular) * objectColor; FragColor = vec4(result, 1.0); } 以上着色器（冯氏着色器）是在片元上进行着色，基础的光照模型也可以考虑在顶点进行着色（Gouraud着色）。其优势在于需要处理的点更少，效率高。然而，顶点着色器中的最终颜色值是仅仅只是那个顶点的颜色值，片段的颜色值是由插值光照颜色所得来的。结果就是这种光照看起来不会非常真实（甚至有些奇怪），除非使用了大量顶点。 3. 材质 根据基础光照模型可知，物体最终的着色情况主要取决于光线和物体材质。通过将光线和物体材质进行封装，可以更加便捷的管理光照和材质。（然而，实际的物体材质很少会完全一致，这里只是最简单的模型） // 封装了光与材质的片元着色器 #version 330 core // 定义物体材质 struct Material { vec3 ambient; vec3 diffuse; vec3 specular; float shininess; }; // 定义光照情况 struct Light { vec3 position; vec3 ambient; vec3 diffuse; vec3 specular; }; out vec4 FragColor; uniform Material material; uniform Light light; uniform vec3 viewPos; in vec3 FragPos; in vec3 Normal; void main() { // 环境光 vec3 ambient = material.ambient * light.ambient; // 漫反射 vec3 norm = normalize(Normal); vec3 lightDir = normalize(light.position - FragPos); float diff = max(dot(norm, lightDir), 0.0); vec3 diffuse = material.diffuse * diff * light.diffuse; // 镜面光照 vec3 viewDir = normalize(viewPos - FragPos); vec3 reflectDir = reflect(-lightDir, norm); // reflect()要求向量的方向从片元指向光源，这与lightDir正相反 float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); vec3 specular = material.specular * spec * light.ambient; vec3 result = ambient + diffuse + specular; FragColor = vec4(result, 1.0); } 4. 光照贴图 上一章定义了一个最简单的材质模型，本章通过引入漫反射贴图和镜面光贴图以期让材质更加真实。漫反射贴图的引入可以让我们省略环境光材质的定义，因为环境光颜色在几乎所有情况下都等于漫反射颜色。镜面光贴图的引入是为了让物体的高光呈现更加真实的效果。 下面的代码除了引入反射贴图和镜面光贴图外，还引入了发射光贴图（发射光贴图是指物体本身会发光的情况。冯氏模型中，我们虽然可以模仿物体本身发光，但却难以反映出这些光对于周围物体的着色影响。） #version 330 core // 定义物体材质 struct Material { // 移除环境光，因为环境光颜色在几乎所有情况下都等于漫反射颜色 sampler2D diffuse; // 根据材质判断物体表面是否应该形成高光 sampler2D specular; // 物体自身发光贴图 sampler2D emission; float shininess; }; // 定义光照情况 struct Light { vec3 position; vec3 ambient; vec3 diffuse; vec3 specular; }; out vec4 FragColor; uniform Material material; uniform Light light; uniform vec3 viewPos; in vec2 TexCoords; // 获取材质坐标 in vec3 FragPos; in vec3 Normal; void main() { // 环境光 vec3 ambient = light.ambient * vec3(texture(material.diffuse, TexCoords)); // 漫反射 vec3 norm = normalize(Normal); vec3 lightDir = normalize(light.position - FragPos); float diff = max(dot(norm, lightDir), 0.0); vec3 diffuse = light.diffuse * diff * vec3(texture(material.diffuse, TexCoords)); // 镜面光照 vec3 viewDir = normalize(viewPos - FragPos); vec3 reflectDir = reflect(-lightDir, norm); // reflect()要求向量的方向从片元指向光源，这与lightDir正相反 float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); vec3 specular = light.ambient * spec * vec3(texture(material.specular, TexCoords));; // 发光 vec3 emission = texture(material.emission, TexCoords).rgb; vec3 result = ambient + diffuse + specular + emission; FragColor = vec4(result, 1.0); } 5. 透光物 本部分主要讨论不同的光源类型对于着色的影响。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:4:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.1 平行光 平行光模拟的是无限远处光源对于着色器的影响（类似于太阳）。因此再着色器中定义光源时，我们不再需要知道光源的位置，而是定义光照向量。 struct Light { // vec3 position; // 使用定向光就不再需要了 vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular; }; ... void main() { vec3 lightDir = normalize(-light.direction); ... } 注意到上面求光照方向时，对方向取反，这是因为定义时通常习惯定义光到片元的向量。而在实际使用时，我们是用片元到光的向量来计算漫反射和镜面反射的。 // 设置光照方向（我们总是定义从光到场景的方向，很容易看出这是一个向下照射的光） lightingShader.setVec3(\"light.direction\", -0.2f, -1.0f, -0.3f); ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:5:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.2 点光源 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:6:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.2.1 衰减 与平行光不同，点光源(Point Light)需要考虑能量的衰减（Attenuation）。能量衰减与光源到着色点间的距离成反比，衰减公式的定义如下： $$F_{at}=1.0/(K_c + k_l*d+k_q*d^2)$$ 其中$k_c$是常数项衰减因子，始终定义为1.0，保证分母始终大于1.0。$k_l$和$k_q$分别为一次项和二次项。从定义可以看出，由于二次项的存在，光线会在大部分时候以线性的方式衰退，直到距离变得足够大，让二次项超过一次项，光的强度会以更快的速度下降。 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:6:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.2.2 选值 衰减因子的选择是一个问题。正确地设定它们的值取决于很多因素：环境、希望光覆盖的距离、光的类型等。在大多数情况下，这都是经验的问题，以及适量的调整。下面这个表格显示了模拟一个（大概）真实的，覆盖特定半径（距离）的光源时，这些项可能取的一些值。第一列指定的是在给定的三项时光所能覆盖的距离。这些值是大多数光源很好的起始点，它们由Ogre3D的Wiki所提供： 范围 常数项 一次项 二次项 7 1.0 0.7 1.8 13 1.0 0.35 0.44 20 1.0 0.22 0.20 32 1.0 0.14 0.07 50 1.0 0.09 0.032 65 1.0 0.07 0.017 100 1.0 0.045 0.0075 160 1.0 0.027 0.0028 200 1.0 0.022 0.0019 325 1.0 0.014 0.0007 600 1.0 0.007 0.0002 3250 1.0 0.0014 0.000007 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:6:2","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.2.3 实现衰减 为了实现衰减，需要在着色器中光的定义里添加常数项，一次项和二次项。并根据衰减定义，将器附加到光照上。（对于环境光，我们可以将环境光分量保持不变，让环境光照不会随着距离减少，但是如果我们使用多于一个的光源，所有的环境光分量将会开始叠加，所以在这种情况下我们也希望衰减环境光照） struct Light { ... float constant; float linear; float quadratic; }; ... void main { ... float distance = length(light.position - FragPos); float attenuation = 1.0 / (light.constant + light.linear * distance + light.quadratic * (distance * distance)); ... ambient *= attenuation; diffuse *= attenuation; specular *= attenuation; } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:6:3","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.4 聚光 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:7:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.4.1 聚光的定义 聚光（Spotlight）是位于环境中某个位置的光源，它只朝一个特定方向而不是所有方向照射光线。这样的结果就是只有在聚光方向的特定半径内的物体才会被照亮，其它的物体都会保持黑暗。聚光很好的例子就是路灯或手电筒。 OpenGL中定义的聚光用一个世界空间位置、一个方向和一个切光角(Cutoff Angle)来表示的，切光角指定了聚光的半径（圆锥的半径）。对于每个片段，我们会计算片段是否位于聚光的切光方向之间（也就是在锥形内），如果是的话，我们就会相应地照亮片段。下面这张图会让你明白聚光是如何工作的： LightDir：从片段指向光源的向量。 SpotDir：聚光所指向的方向。 $ϕ$：指定了聚光半径的切光角。落在这个角度之外的物体都不会被这个聚光所照亮。 $θ$：LightDir向量和SpotDir向量之间的夹角。在聚光内部的话θ值应该比ϕ值小。 通过公式$LightDir·SpotDir$可以获取$θ$的余弦值，并将它与与切光角$ϕ$对比。（注意，这里用的是余弦值！） ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:7:1","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.2 手电筒 手电筒（Flashlight）是一种典型的聚光光源，其位置和方向会随着玩家的位置和方向不断更新。（考虑到聚光的特性，其对环境光贡献通常较小，甚至没有） // 定义手电筒 struct Light { vec3 position; vec3 direction; float cutOff; ... }; ... void main() { ... float theta = dot(lightDir, normalize(-light.direction)); if(theta \u003e light.cutOff) // //请记住，这里用的是角的余弦而不是度，所以这里用的是\u003e { // 执行光照计算 } else // 否则，使用环境光，让场景在聚光之外时不至于完全黑暗 color = vec4(light.ambient * vec3(texture(material.diffuse, TexCoords)), 1.0); } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:7:2","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"5.3 平滑/软化边缘 按照上述做法，最后得到的效果并不如意，这是因为光照的边缘处的差异过于极端。如下图所示，注意到光边缘处内外明暗十分显著，缺乏平滑过渡。为了让聚光效果显得更加真实，我们需要对边缘做平滑/软化处理。 为了创建一种看起来边缘平滑的聚光，我们需要模拟聚光有一个内圆锥(Inner Cone)和一个外圆锥(Outer Cone)。内圆锥即上面的光照部分，而外圆锥则主要起到让光从内圆锥逐渐变暗直到外圆锥边界的效果。 为了创建一个外圆锥，我们只需要再定义一个余弦值来代表聚光方向向量和外圆锥向量（等于它的半径）的夹角。然后，如果一个片段处于内外圆锥之间，将会给它计算出一个0.0到1.0之间的强度值。如果片段在内圆锥之内，它的强度就是1.0，如果在外圆锥之外强度值就是0.0。公式如下（所有角度都代表余弦值）： $$I=({\\theta}-{\\gamma})/{\\epsilon}$$ 其中，${\\epsilon}={\\phi}-{\\gamma}$是内($\\phi$)外($\\gamma$)圆锥的余弦差值。最终的$I$值就是在当前片段聚光的强度。learnOpenGL中给出了一些设置情况： $\\theta$ $\\theta$(角度) $\\phi$ $\\phi$(角度) $\\gamma$ $\\gamma$(角度) $\\epsilon$ $I$ 0.87 30 0.91 25 0.82 35 0.91 - 0.82 = 0.09 0.87 - 0.82 / 0.09 = 0.56 0.9 26 0.91 25 0.82 35 0.91 - 0.82 = 0.09 0.9 - 0.82 / 0.09 = 0.89 0.97 14 0.91 25 0.82 35 0.91 - 0.82 = 0.09 0.97 - 0.82 / 0.09 = 1.67 0.83 34 0.91 25 0.82 35 0.91 - 0.82 = 0.09 0.83 - 0.82 / 0.09 = 0.11 0.64 50 0.91 25 0.82 35 0.91 - 0.82 = 0.09 0.64 - 0.82 / 0.09 = -2.0 0.966 15 0.9978 12.5 0.953 17.5 0.966 - 0.953 = 0.0448 0.966 - 0.953 / 0.0448 = 0.29 根据以上定义，我们可以重新定义我们的片段着色器： ... struct Light { ... float outerCutOff; // ... }; ... void main // 内外边缘的引入让我们不再需要判断着色片段是否在范围内，因为intensity的计算完成了这个工作 { ... float theta = dot(lightDir, normalize(-light.direction)); float epsilon = light.cutOff - light.outerCutOff; float intensity = clamp((theta - light.outerCutOff) / epsilon, 0.0, 1.0); // 把第一个参数约束在了0.0到1.0之间 ... // 将不对环境光做出影响，让它总是能有一点光 diffuse *= intensity; specular *= intensity; ... } 边缘软化后的效果： 6. 多光源 多光源的本质就是多种类型的光共同作用于物体后产生的着色效果。我们可以将各种光源的着色过程封装为相应的函数，并累加其计算结果得到最后的着色效果。 #version 330 core out vec4 FragColor; // 定义材质 struct Material { sampler2D diffuse; sampler2D specular; float shininess; }; // 定义平行光 struct DirLight { vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular; }; // 定义点光源 struct PointLight { vec3 position; float constant; float linear; float quadratic; vec3 ambient; vec3 diffuse; vec3 specular; }; // 定义聚光 struct SpotLight { vec3 position; vec3 direction; float cutOff; float outerCutOff; float constant; float linear; float quadratic; vec3 ambient; vec3 diffuse; vec3 specular; }; #define NR_POINT_LIGHTS 4 in vec3 FragPos; in vec3 Normal; in vec2 TexCoords; uniform vec3 viewPos; uniform DirLight dirLight; uniform PointLight pointLights[NR_POINT_LIGHTS]; uniform SpotLight spotLight; uniform Material material; // 函数定义 vec3 CalcDirLight(DirLight light, vec3 normal, vec3 viewDir); vec3 CalcPointLight(PointLight light, vec3 normal, vec3 fragPos, vec3 viewDir); vec3 CalcSpotLight(SpotLight light, vec3 normal, vec3 fragPos, vec3 viewDir); void main() { // 属性 vec3 norm = normalize(Normal); vec3 viewDir = normalize(viewPos - FragPos); // 计算平行光 vec3 result = CalcDirLight(dirLight, norm, viewDir); // 计算点光源（由于有四个点光源，故计算四次） for(int i = 0; i \u003c NR_POINT_LIGHTS; i++) result += CalcPointLight(pointLights[i], norm, FragPos, viewDir); // 计算聚光 result += CalcSpotLight(spotLight, norm, FragPos, viewDir); FragColor = vec4(result, 1.0); } // 计算平行光着色情况 vec3 CalcDirLight(DirLight light, vec3 normal, vec3 viewDir) { vec3 lightDir = normalize(-light.direction); // 漫反射 float diff = max(dot(normal, lightDir), 0.0); // 镜面反射 vec3 reflectDir = reflect(-lightDir, normal); float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); // 混合后结果 vec3 ambient = light.ambient * vec3(texture(material.diffuse, TexCoords)); vec3 diffuse = light.diffuse * diff * vec3(texture(material.diffuse, TexCoords)); vec3 specular = light.specular * spec * vec3(texture(material.specular, TexCoords)); return (ambient + diffuse + specular); } // 计算点光源着色情况 vec3 CalcPointLight(PointLight light, vec3 normal, vec3 fragPos, vec3 viewDir) { vec3 lightDir = normalize(light.position - fragPos); // 漫反射 float diff = max(dot(normal, lightDir), 0.0); // 镜面反射 vec3 reflectDir = reflect(-lightDir, normal); float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); // 衰减因子 float distance = length(light.position - fragPos); float attenuation = 1.0 / (light.constant + light.linear * distance + light.quadratic * (distance * distanc","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/:7:3","tags":["计算机图形学"],"title":"OpenGL学习笔记——光照","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%89%E7%85%A7/"},{"categories":["OpenGL学习笔记"],"content":"1. 你好，三角形 基于OpenGL绘制三角形 #include \u003cglad/glad.h\u003e#include \u003cGLFW/glfw3.h\u003e#include \u003ciostream\u003e const char* vertexShaderSource = \"#version 330 core\\n\" \"layout (location = 0) in vec3 aPos;\\n\" \"void main()\\n\" \"{\\n\" \" gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\\n\" \"}\\0\"; const char* fragmentShaderSource = \"#version 330 core\\n\" \"out vec4 FragColor;\\n\" \"void main()\\n\" \"{\\n\" \" FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\\n\" \"}\\0\"; // 对窗口注册一个回调函数(Callback Function)，它会在每次窗口大小被调整的时候被调用 void framebuffer_size_callback(GLFWwindow* window, int width, int height) { glViewport(0, 0, width, height); } // 处理输入 void processInput(GLFWwindow* window) { if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true); } int main() { glfwInit(); // 初始化GLFW GLFWwindow* window = glfwCreateWindow(800, 600, \"LearnOpenGL\", NULL, NULL); // 创建窗口 if (window == NULL) { std::cout \u003c\u003c \"Failed to create GLFW window\" \u003c\u003c std::endl; glfwTerminate(); return -1; } // 将该窗口作为当前线程的主上下文 glfwMakeContextCurrent(window); //GLAD是管理OpenGL指针的，在调用任何OpenGL的函数之前需要初始化GLAD if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cout \u003c\u003c \"Failed to initialize GLAD\" \u003c\u003c std::endl; return -1; } // 设置视口维度 // glViewport函数前两个参数控制窗口左下角的位置 // 第三个和第四个参数控制渲染窗口的宽度和高度（像素） glViewport(0, 0, 800, 600); // 监听窗口大小变化 glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); // 定义顶点着色器 unsigned int vertexShader; vertexShader = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertexShader, 1, \u0026vertexShaderSource, NULL); glCompileShader(vertexShader); // 检测是否编译成功 int success; char infoLog[512]; // 存储错误信息的容器(如果有的话) glGetShaderiv(vertexShader, GL_COMPILE_STATUS, \u0026success); if (!success) { glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::VERTEX::COMPILATION_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; } // 定义片元着色器 unsigned int fragmentShader; fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragmentShader, 1, \u0026fragmentShaderSource, NULL); glCompileShader(fragmentShader); glGetShaderiv(fragmentShader, GL_COMPILE_STATUS, \u0026success); if (!success) { glGetShaderInfoLog(fragmentShader, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; } // 定义着色器程序 unsigned int shaderProgram; shaderProgram = glCreateProgram(); glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader); glLinkProgram(shaderProgram); // 检测是否链接成功 glGetProgramiv(shaderProgram, GL_LINK_STATUS, \u0026success); if (!success) { glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::PROGRAM::LINK_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; } // 链接完毕后，我们已经不再需要着色器了 glDeleteShader(vertexShader); glDeleteShader(fragmentShader); float vertices[] = { 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f, // 左上角 }; // 定义三角形的索引，使用这种数据结构可以节约内存空间 unsigned int indices[] = { // 注意索引从0开始! 0, 1, 3, // 第一个三角形 1, 2, 3, // 第二个三角形 }; // 定义顶点缓冲对象 unsigned int VBO; glGenBuffers(1, \u0026VBO); // 定义顶点数组对象 unsigned int VAO; glGenVertexArrays(1, \u0026VAO); // 定义索引缓冲对象 unsigned int EBO; glGenBuffers(1, \u0026EBO); // 1. 绑定VAO glBindVertexArray(VAO); // 2. 把顶点数组复制到缓冲中供OpenGL使用 glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); // 3. 复制我们的索引数组到一个索引缓冲中，供OpenGL使用 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); // 4. 设置顶点属性指针 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); /* glVertexAttribPointer(): 第一个参数指定要配置的顶点属性 第二个参数指定顶点属性的大小。顶点属性是一个vec3，它由3个值组成，所以大小是3。 第三个参数指定数据的类型，这里是GL_FLOAT 第四个参数定义我们是否希望数据被标准化(Normalize)。如果我们设置为GL_TRUE， 所有数据都会被映射到0（对于有符号型signed数据是-1）到1之间。我们把它设置为GL_FALSE。 第五个参数叫做步长(Stride)，它告诉我们在连续的顶点属性组之间的间隔 从这个属性第二次出现的地方到整个数组0位置之间有多少字节 最后一个参数的类型是void*，所以需要我们进行这个奇怪的强制类型转换。 它表示位置数据在缓冲中起始位置的偏移量(Offset)。 */ // glPolygonMode(GL_FRONT_AND_BACK, GL_LINE); // 用于决定绘制风格，默认为GL_F","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:0:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"2.1 着色器头文件 通过对着色器进行封装，可以简化我们的操作 #ifndef SHADER_H #define SHADER_H #include \u003cglad/glad.h\u003e #include \u003cstring\u003e#include \u003cfstream\u003e#include \u003csstream\u003e#include \u003ciostream\u003e class Shader { public: // 程序ID unsigned int ID; // 构造器读取并构建着色器 Shader(const GLchar* vertexPath, const GLchar* fragmentPath); // 使用/激活程序 void use(); // uniform工具函数 void setBool(const std::string\u0026 name, bool value) const; void setInt(const std::string\u0026 name, int value) const; void setFloat(const std::string\u0026 name, float value) const; }; Shader::Shader(const GLchar* vertexPath, const GLchar* fragmentPath) { // 1. 从文件路径中获取顶点/片段着色器 std::string vertexCode; std::string fragmentCode; std::ifstream vShaderFile; std::ifstream fShaderFile; // 保证ifstream对象可以抛出异常： vShaderFile.exceptions(std::ifstream::failbit | std::ifstream::badbit); fShaderFile.exceptions(std::ifstream::failbit | std::ifstream::badbit); try { // 打开文件 vShaderFile.open(vertexPath); fShaderFile.open(fragmentPath); std::stringstream vShaderStream, fShaderStream; // 读取文件的缓冲内容到数据流中 vShaderStream \u003c\u003c vShaderFile.rdbuf(); fShaderStream \u003c\u003c fShaderFile.rdbuf(); // 关闭文件处理器 vShaderFile.close(); fShaderFile.close(); // 转换数据流到string vertexCode = vShaderStream.str(); fragmentCode = fShaderStream.str(); } catch (std::ifstream::failure e) { std::cout \u003c\u003c \"ERROR::SHADER::FILE_NOT_SUCCESFULLY_READ\" \u003c\u003c std::endl; } const char* vShaderCode = vertexCode.c_str(); const char* fShaderCode = fragmentCode.c_str(); // 2. 编译着色器 unsigned int vertex, fragment; int success; char infoLog[512]; // 顶点着色器 vertex = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertex, 1, \u0026vShaderCode, NULL); glCompileShader(vertex); // 打印编译错误（如果有的话） glGetShaderiv(vertex, GL_COMPILE_STATUS, \u0026success); if (!success) { glGetShaderInfoLog(vertex, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::VERTEX::COMPILATION_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; }; // 片元着色器 fragment = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragment, 1, \u0026fShaderCode, NULL); glCompileShader(fragment); // 打印编译错误（如果有的话） glGetShaderiv(fragment, GL_COMPILE_STATUS, \u0026success); if (!success) { glGetShaderInfoLog(fragment, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; } // 着色器程序 ID = glCreateProgram(); glAttachShader(ID, vertex); glAttachShader(ID, fragment); glLinkProgram(ID); // 打印连接错误（如果有的话） glGetProgramiv(ID, GL_LINK_STATUS, \u0026success); if (!success) { glGetProgramInfoLog(ID, 512, NULL, infoLog); std::cout \u003c\u003c \"ERROR::SHADER::PROGRAM::LINKING_FAILED\\n\" \u003c\u003c infoLog \u003c\u003c std::endl; } // 删除着色器，它们已经链接到我们的程序中了，已经不再需要了 glDeleteShader(vertex); glDeleteShader(fragment); } void Shader::use() { glUseProgram(ID); } void Shader::setBool(const std::string\u0026 name, bool value) const { glUniform1i(glGetUniformLocation(ID, name.c_str()), (int)value); } void Shader::setInt(const std::string\u0026 name, int value) const { glUniform1i(glGetUniformLocation(ID, name.c_str()), value); } void Shader::setFloat(const std::string\u0026 name, float value) const { glUniform1f(glGetUniformLocation(ID, name.c_str()), value); } #endif // !SHADER_H ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:1:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"2.2 简单的顶点着色器和片元着色器 顶点着色器： #version 330 core layout (location = 0) in vec3 aPos; // 位置变量的属性位置值为 0 layout (location = 1) in vec3 aColor; // 颜色变量的属性位置值为 1 out vec3 ourColor; // 向片段着色器输出一个颜色 void main() { gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0); // 把一个vec3作为vec4的构造器的参数 ourColor = aColor; } 片元着色器： #version 330 core out vec4 FragColor; in vec3 ourColor; void main() { FragColor = vec4(ourColor, 1.0); } ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:2:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"2.3 头文件调用样例 #include \u003cglad/glad.h\u003e#include \u003cGLFW/glfw3.h\u003e#include \u003ciostream\u003e#include \u003cShader.h\u003e void framebuffer_size_callback(GLFWwindow* window, int width, int height) { glViewport(0, 0, width, height); } void processInput(GLFWwindow* window) { if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true); } int main() { glfwInit(); GLFWwindow* window = glfwCreateWindow(800, 600, \"LearnOpenGL\", NULL, NULL); if (window == NULL) { std::cout \u003c\u003c \"Failed to create GLFW window\" \u003c\u003c std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cout \u003c\u003c \"Failed to initialize GLAD\" \u003c\u003c std::endl; return -1; } glViewport(0, 0, 800, 600); glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); // 创建并编译我们的渲染器 // ------------------------------------ Shader ourShader(\"D:/C++ Project/OpenGL Project/shaders/3.3.shader.vs\", \"D:/C++ Project/OpenGL Project/shaders/3.3.shader.fs\"); // 你可以为编译器文件赋予任意的名称 float vertices[] = { // 位置 // 颜色 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, // 左下 0.0f, 0.5f, 0.0f, 0.0f, 0.0f, 1.0f // 顶部 }; // 定义顶点缓冲对象 unsigned int VBO; glGenBuffers(1, \u0026VBO); // 定义顶点数组对象 unsigned int VAO; glGenVertexArrays(1, \u0026VAO); // 1. 绑定VAO glBindVertexArray(VAO); // 2. 把顶点数组复制到缓冲中供OpenGL使用 glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); // 3. 设置顶点属性指针: 位置，颜色(颜色的offset是 3 * sizeof(float)) glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3 * sizeof(float))); glEnableVertexAttribArray(1); while (!glfwWindowShouldClose(window)) { // 输入 processInput(window); // 清屏 glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // 渲染指令 ourShader.use(); glBindVertexArray(VAO); // 由于我们只有一个VAO，所以没有必要每次都绑定它，但是我们这样做是为了让事情更有条理 glDrawArrays(GL_TRIANGLES, 0, 3); // 检查并调用事件，交换缓冲 glfwPollEvents(); glfwSwapBuffers(window); } // 退出前清理 glDeleteVertexArrays(1, \u0026VAO); glDeleteBuffers(1, \u0026VBO); glfwTerminate(); return 0; } 3. 纹理 纹理就是物体自身固有的属性，通常由艺术家们负责定义。对于程序员而言，主要工作在于保证材质能够准确地被贴到物体上。(注意，材质激活的顺序要与材质加载顺序保持一致！) // 加载2D材质函数 unsigned int loadTexture(char const* path) { unsigned int textureID; glGenTextures(1, \u0026textureID); // stbi_set_flip_vertically_on_load(true); // 很多图片的y轴位置在顶部，而OpenGL的y轴位置在底部。调用这条指令可以完成图片的颠倒 int width, height, nrComponents; unsigned char* data = stbi_load(path, \u0026width, \u0026height, \u0026nrComponents, 0); if (data) { GLenum format; if (nrComponents == 1) format = GL_RED; else if (nrComponents == 3) format = GL_RGB; else if (nrComponents == 4) format = GL_RGBA; glBindTexture(GL_TEXTURE_2D, textureID); glTexImage2D(GL_TEXTURE_2D, 0, format, width, height, 0, format, GL_UNSIGNED_BYTE, data); glGenerateMipmap(GL_TEXTURE_2D); // 纹理环绕。下面两条指令指定了s轴和t轴的纹理环绕方式 // GL_REPEAT 对纹理的默认行为。重复纹理图像。 // GL_MIRRORED_REPEAT 和GL_REPEAT一样，每次重复图片是镜像放置的。 // GL_CLAMP_TO_EDGE 纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果。 // GL_CLAMP_TO_BORDER 超出的坐标为用户指定的边缘颜色。 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); // 纹理过滤。下面两条指定了近处和远处的纹理过滤方式 // GL_LINEAR表示采用双线性插值进行采样，GL_NEAREST表示采用最近邻采样 // 多级渐远纹理(mipmap)——解决远处纹理分辨率过高导致贴图不准确的问题，同时节省性能消耗。 // GL_NEAREST_MIPMAP_NEAREST 使用最邻近的多级渐远纹理来匹配像素大小，并使用邻近插值进行纹理采样 // GL_LINEAR_MIPMAP_NEAREST 使用最邻近的多级渐远纹理级别，并使用线性插值进行采样 // GL_NEAREST_MIPMAP_LINEAR 在两个最匹配像素大小的多级渐远纹理之间进行线性插值，使用邻近插值进行采样 // GL_LINEAR_MIPMAP_LINEAR 在两个邻近的多级渐远纹理之间使用线性插值，并使用线性插值进行采样 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR_MIPMAP_LINEAR); stbi_image_free(data); } else { std::cout \u003c\u003c \"Texture failed to load at path: \" \u003c\u003c path \u003c\u003c std::endl; stbi_image_free(data); } return textureID; } 4. 变换、坐标系统、摄像机 ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:3:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"4.0 GLM 由于OpenGL没有自带任何的矩阵和向量知识，为了能够使用我们需要自定义相应的数学类和函数。幸运的是，这样的工作已经有人做过了，通过调用GLM库，我们可以很愉快的跳过自己定义的部分。 GLM是OpenGL Mathematics的缩写，它是一个只有头文件的库，也就是说我们只需包含对应的头文件就行了，不用链接和编译。GLM可以在它们的网站上下载。把头文件的根目录复制到你的includes文件夹，然后你就可以使用这个库了。 GLM的大多数功能都可以从下面这3个头文件中找到: #include \u003cglm/glm.hpp\u003e#include \u003cglm/gtc/matrix_transform.hpp\u003e#include \u003cglm/gtc/type_ptr.hpp\u003e （Tips: 0.9.9版以后，默认矩阵会被初始化位一个零矩阵，为了能够顺利使用，需要将其初始化为单位矩阵） ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:4:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"4.1 总述 本部分主要涉及图形学中三维空间到二维空间的模型变换问题。其中最核心的部分在于model, view, projection三种变换。 model——旨在三维空间中对模型进行各种变换，包括缩放、旋转、位移（先缩放，再位移）。为了能够使得偏移可以被完成，故存放三维物体的实际是一个4x4的矩阵。相应的，空间中的向量也包含4个变量，形如$(x,y,z,w)$。引入多一维度，也是为了避免旋转过程中出现万向节死锁（Gimbal Lock, 万向节死锁的出现是因为我们始终按照某一种固定顺序对3x3的三维空间物体做旋转） (引入$w$分量后坐标变为齐次坐标。当$w$为1，说明其为三维空间上的一个点；当$w$为零，则说明其为三维空间上的向量。我们可以通过让 $x$, $y$, $z$ 分量除以 $w$ 来它们的范围落到 [-1, 1] 之间) view——视图主要是呈现在屏幕上的画面，通过视图变换，可以决定3D空间中的物体具体要投影到世界坐标系中的哪个平面当中。 /*LookAT()函数用以创建观察矩阵*/ // Custom implementation of the LookAt function glm::mat4 calculate_lookAt_matrix(glm::vec3 position, glm::vec3 target, glm::vec3 worldUp) { // 1. Position = known // 2. Calculate cameraDirection glm::vec3 zaxis = glm::normalize(position - target); // 3. Get positive right axis vector glm::vec3 xaxis = glm::normalize(glm::cross(glm::normalize(worldUp), zaxis)); // 4. Calculate camera up vector glm::vec3 yaxis = glm::cross(zaxis, xaxis); // Create translation and rotation matrix // In glm we access elements as mat[col][row] due to column-major layout glm::mat4 translation = glm::mat4(1.0f); // Identity matrix by default translation[3][0] = -position.x; // Third column, first row translation[3][1] = -position.y; translation[3][2] = -position.z; glm::mat4 rotation = glm::mat4(1.0f); rotation[0][0] = xaxis.x; // First column, first row rotation[1][0] = xaxis.y; rotation[2][0] = xaxis.z; rotation[0][1] = yaxis.x; // First column, second row rotation[1][1] = yaxis.y; rotation[2][1] = yaxis.z; rotation[0][2] = zaxis.x; // First column, third row rotation[1][2] = zaxis.y; rotation[2][2] = zaxis.z; // Return lookAt matrix as combination of translation and rotation matrix return rotation * translation; // Remember to read from right to left (first translation then rotation) } // Don't forget to replace glm::lookAt with your own version // view = glm::lookAt(glm::vec3(camX, 0.0f, camZ), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); view = calculate_lookAt_matrix(glm::vec3(camX, 0.0f, camZ), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); projection——投影的主要作用在于把三维空间中的物体投影到二维平面上，主要有正射投影和透视投影。正射投影比较简单，可视范围是一个长方体，直接把3D空间中长方体范围内的点投影到屏幕上即可。投射投影则更加自然，从摄像机出发，其可视范围是一个视锥体，需要先将其转换为长方体，然后再进行投影。 glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); // 它的第一个参数定义了fov(Field of View)的值，并且设置了观察空间的大小。如果想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值。 // 第二个参数设置了宽高比，由视口的宽除以高所得。 // 第三和第四个参数设置了平截头体的近和远平面。我们通常设置近距离为0.1f，而远距离设为100.0f。 透视投影矩阵： ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:5:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"4.2 摄像机类 定义一个摄像机类可以帮助我们更方便管理摄像机的相关操作。摄像机在游戏中意味着玩家的眼睛，直接反映了玩家所能看到的游戏画面。将其封装为一个类，有助于我们更加便捷的管理游戏所呈现的视觉效果。 #ifndef CAMERA_H #define CAMERA_H #include \u003cglad/glad.h\u003e#include \u003cglm/glm.hpp\u003e#include \u003cglm/gtc/matrix_transform.hpp\u003e #include \u003cvector\u003e // 定义相机移动的几个可能选项，用作抽象以远离特定于窗口系统的输入法 enum Camera_Movement { FORWARD, BACKWARD, LEFT, RIGHT }; // 默认摄像机的值 const float YAW = -90.0f; const float PITCH = 0.0f; const float SPEED = 2.5f; const float SENSITIVITY = 0.1f; const float ZOOM = 45.0f; // 一个抽象的相机类，处理输入并计算在OpenGL中使用的对应的Euler角，向量和矩阵 class Camera { public: // 摄像机属性 glm::vec3 Position; // 坐标 glm::vec3 Front; // 摄像机朝向 glm::vec3 Up; // 上轴，代表摄像机空间的y轴的正方向 glm::vec3 Right; // 右轴，代表摄像机空间的x轴的正方向 glm::vec3 WorldUp; // 欧拉角 float Yaw; // 偏航角 float Pitch; // 俯仰角 // 相机选项 float MovementSpeed; float MouseSensitivity; float Zoom; // 用向量构造 Camera(glm::vec3 position = glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f), float yaw = YAW, float pitch = PITCH) : Front(glm::vec3(0.0f, 0.0f, -1.0f)), MovementSpeed(SPEED), MouseSensitivity(SENSITIVITY), Zoom(ZOOM) { Position = position; WorldUp = up; Yaw = yaw; Pitch = pitch; updateCameraVectors(); } // 用标量值构造 Camera(float posX, float posY, float posZ, float upX, float upY, float upZ, float yaw, float pitch) : Front(glm::vec3(0.0f, 0.0f, -1.0f)), MovementSpeed(SPEED), MouseSensitivity(SENSITIVITY), Zoom(ZOOM) { Position = glm::vec3(posX, posY, posZ); WorldUp = glm::vec3(upX, upY, upZ); Yaw = yaw; Pitch = pitch; updateCameraVectors(); } // 返回使用Euler Angles和LookAt Matrix计算的视图矩阵 glm::mat4 GetViewMatrix() { return glm::lookAt(Position, Position + Front, Up); } // 处理从任何类似键盘的输入系统接收到的输入，接受摄像机定义的enum形式的输入参数（以从窗口系统中抽象出来） void ProcessKeyboard(Camera_Movement direction, float deltaTime) { float velocity = MovementSpeed * deltaTime; if (direction == FORWARD) Position += Front * velocity; if (direction == BACKWARD) Position -= Front * velocity; if (direction == LEFT) Position -= Right * velocity; if (direction == RIGHT) Position += Right * velocity; } // 处理从鼠标输入系统接收到的输入，预计其在x和y方向上的偏移值。 void ProcessMouseMovement(float xoffset, float yoffset, GLboolean constrainPitch = true) { xoffset *= MouseSensitivity; yoffset *= MouseSensitivity; Yaw += xoffset; Pitch += yoffset; // 确保当pitch超出范围时，屏幕不会翻转 if (constrainPitch) { if (Pitch \u003e 89.0f) Pitch = 89.0f; if (Pitch \u003c -89.0f) Pitch = -89.0f; } // 使用更新的欧拉角更新Front, Right, Up 向量 using the updated Euler angles updateCameraVectors(); } // 处理从鼠标滚轮收到的输入，只需要考虑垂直轮轴 void ProcessMouseScroll(float yoffset) { Zoom -= (float)yoffset; if (Zoom \u003c 1.0f) Zoom = 1.0f; if (Zoom \u003e 45.0f) Zoom = 45.0f; } private: // 根据相机的（更新的）欧拉角计算前向量 void updateCameraVectors() { // 计算新的 Front vector glm::vec3 front; front.x = cos(glm::radians(Yaw)) * cos(glm::radians(Pitch)); front.y = sin(glm::radians(Pitch)); front.z = sin(glm::radians(Yaw)) * cos(glm::radians(Pitch)); Front = glm::normalize(front); // 类似地，重新计算 Right 和 Up vector Right = glm::normalize(glm::cross(Front, WorldUp)); // 对向量进行归一化，因为您向上或向下看的次数越多，它们的长度就越接近0，这会导致运动变慢。 Up = glm::normalize(glm::cross(Right, Front)); } }; #endif ","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:6:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["OpenGL学习笔记"],"content":"4.3 代码示例 // 基于摄像机类，使用MVP矩阵转换 #define STB_IMAGE_IMPLEMENTATION #include \"stb_image.h\" #include \u003cglad/glad.h\u003e#include \u003cGLFW/glfw3.h\u003e#include \u003ciostream\u003e#include \u003cShader.h\u003e#include \u003cCamera.h\u003e #include \u003cglm/glm.hpp\u003e#include \u003cglm/gtc/matrix_transform.hpp\u003e#include \u003cglm/gtc/type_ptr.hpp\u003e // 定义屏幕属性 const unsigned int SCR_WIDTH = 800; const unsigned int SCR_HEIGHT = 600; // 摄像机 Camera camera(glm::vec3(0.0f, 0.0f, 3.0f)); float lastX = SCR_WIDTH / 2.0f; float lastY = SCR_HEIGHT / 2.0f; bool firstMouse = true; // 时间 float deltaTime = 0.0f; // 当前帧与上一帧的时间差 float lastFrame = 0.0f; // 定义回调函数 void framebuffer_size_callback(GLFWwindow* window, int width, int height); void processInput(GLFWwindow* window, Shader\u0026 ourShader); void mouse_callback(GLFWwindow* window, double xpos, double ypos); void scroll_callback(GLFWwindow* window, double xoffset, double yoffset); int main() { glfwInit(); GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, \"LearnOpenGL\", NULL, NULL); if (window == NULL) { std::cout \u003c\u003c \"Failed to create GLFW window\" \u003c\u003c std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cout \u003c\u003c \"Failed to initialize GLAD\" \u003c\u003c std::endl; return -1; } glViewport(0, 0, SCR_WIDTH, SCR_HEIGHT); glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); glfwSetCursorPosCallback(window, mouse_callback); glfwSetScrollCallback(window, scroll_callback); // 创建并编译渲染器 Shader ourShader(\"E:/OpenGL Project/Project1/shaders/3.3.shader.vs\", \"E:/OpenGL Project/Project1/shaders/3.3.shader.fs\"); float vertices[] = { // ---- 位置 ---- - 纹理坐标 - -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 1.0f, 1.0f, -0.5f, 0.5f, 0.5f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, 0.5f, -0.5f, 1.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 1.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f }; // 立方体在世界空间的位置 glm::vec3 cubePositions[] = { glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(2.0f, 5.0f, -15.0f), glm::vec3(-1.5f, -2.2f, -2.5f), glm::vec3(-3.8f, -2.0f, -12.3f), glm::vec3(2.4f, -0.4f, -3.5f), glm::vec3(-1.7f, 3.0f, -7.5f), glm::vec3(1.3f, -2.0f, -2.5f), glm::vec3(1.5f, 2.0f, -2.5f), glm::vec3(1.5f, 0.2f, -1.5f), glm::vec3(-1.3f, 1.0f, -1.5f) }; // 定义顶点缓冲、顶点数组 unsigned int VBO, VAO; glGenBuffers(1, \u0026VBO); glGenVertexArrays(1, \u0026VAO); // 绑定VAO glBindVertexArray(VAO); // 把顶点数组复制到缓冲中供OpenGL使用 glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); // 设置顶点位置 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 5 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); // 设置顶点纹理坐标 glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 5 * sizeof(float), (void*)(3 * sizeof(float))); glEnableVertexAttribArray(1); unsigned int texture1, texture2; // 创建纹理1 glGenTextures(1, \u0026texture1); glBindTexture(GL_TEXTURE_2D, texture1); // 为当前绑定的纹理对象设置环绕、过滤方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG","date":"2021-05-26","objectID":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/:7:0","tags":["计算机图形学"],"title":"OpenGL学习笔记——基础部分","uri":"/opengl%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文是增量学习的经典论文，发表于CVPR 2017，基于pytorch的代码在此处。 本文是rehearsal策略的经典算法，其核心点主要是：第一，分类采取了NME（nearest-mean-of-exemplars）；第二，基于herding的优先级筛选样例（保留距离均值更近的样例）；第三，使用知识蒸馏和原型预演进行表征学习。 知识蒸馏由Hinton团队提出，最初用于模型间的知识迁移。由于另外一篇经典的增量学习论文LwF，知识蒸馏被用到增量学习中。 NME相较于nearest-class-mean(NCM)的优势在于它不需要保存所有的原始样本，而是通过计算样本的平均特征向量后。 herding 策略是 rehearsal 中很常见的策略，它主张选择最靠近均值的数据以确保样例集能够代表数据的核心知识。 值得一提的是，本文采用了固定样例集大小的策略来节省样例集存储空间。具体而言，对于CIFAR-100，iCaRL固定了样例集大小 $m = 2000 $，每当有新类加入，样例集中保存的各种类的数目都会按比例缩小。其筛选的标准还是基于与均值的距离。 固定样例集大小的规则目前已经被广泛采纳，对于回溯而言，许多研究者们默认了采用$m=2000$的标准，例如Mnemonics Training 训练过程 Algorithm 1 给出了iCaRL的增量训练过程，Algorithm 3 给出了iCaRL如何进行表示学习 模型：32-layer resnet (For CIFAR-100); 在特征提取部分使用CNN网络，然后是单个分类层，其 sigmoid 输出节点与迄今为止观察到的类一样多。对于任意的类 $y\\in{1,…,t}$，网络的输出结果为（sigmoid层用于模型的损失函数构造，让模型参数得以训练，实际分类则采用NME）： $$g_y(x)=\\frac{1}{1+exp(-\\alpha(x))} \\quad with \\quad \\alpha_y(x)=w_{y}^t\\varphi(x)$$ 实验结果 Kuzborskij等人的研究表明，在向现有的线性多类分类器中添加新类时，只要能够从所有类的少量数据中重新训练分类器，就可以避免精度损失。这说明了Rehearsal在缓解灾难性遗忘方面的效果。 基于Rehearsal的研究主要有两各分关注点，其一是如何让少量数据更好的发挥作用，其二是如何筛选少量数据。 ","date":"2021-05-17","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——iCaRL: Incremental Classifier and Representation Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于CVPR 2019，复现代码见此。 LUCIR同样是致力于缓解rehearsal中不平衡问题，如 Fig.1 所示，本文指出不平衡的数据主要带来了三种问题：(1) 量级不平衡：新类权重向量的量级明显高于旧类； (2) 偏差：之前的知识，即旧类的特征和权重向量之间的关系没有很好地保留； (3)歧义：新类的权重向量与旧类的权重向量接近，往往会导致歧义。 方法 ","date":"2021-05-13","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Learning a Unified Classifier Incrementally via Rebalancing","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/"},{"categories":["论文笔记——深度学习"],"content":"Cosine Normalization 如 Fig.3 所示，由于类别不平衡，新类别的embedding和bias明显高于旧类别。LUCIR提出在最后一层使用 cosine normalization： $$p_i(x)=\\frac{exp(\\eta\u003c\\overline{\\theta}_i,\\overline{f}(x)\u003e)}{\\sum_jexp(\\eta\u003c\\overline{\\theta}_j,\\overline{f}(x)\u003e)}$$ 其中，$f$是特征提取器，$\\theta$是权重，$\\overline{v}=v/||v||_2$代表$l_2-normalized$向量，$\u003c\\overline{v}_1,\\overline{v}_2\u003e=\\overline{v}_1^T\\overline{v}_2$衡量了两个标准向量的余弦相似度。引入可学习标量$η$来控制$softmax$分布的峰值，因为$\u003c\\overline{v}_1,\\overline{v}_2\u003e$的范围被限制在[−1, 1]。它可以有效地消除因幅度显着差异而引起的偏差。 对于蒸馏损失，由于原始模型中的标量 $η$与当前网络中的标量 $η$ 不同，因此模拟 $softmax$ 之前的分数而不是 $softmax$ 之后的概率是合理的。 还值得注意的是，由于余弦归一化，$softmax$ 之前的分数都在相同的范围内（即 [-1, 1]），因此具有可比性。 形式上，蒸馏损失更新为： $$L_{dis}^C(x)=-\\sum_{i=1}^{|C_0|}||\u003c\\overline{\\theta}_i,\\overline{f}(x)\u003e- \u003c\\overline{\\theta}_i^{*},\\overline{f}^{*}(x)||$$ ","date":"2021-05-13","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/:1:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Learning a Unified Classifier Incrementally via Rebalancing","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/"},{"categories":["论文笔记——深度学习"],"content":"Less-Forget Constraint 如 Fig.4 所示，$L^C_{dis}$主要考虑局部几何结构，即归一化特征与旧类嵌入之间的夹角，此约束无法阻止嵌入和特征完全旋转。为了加强对已有知识的约束，LUCIR建议修复旧的类嵌入，并计算一个新的特征提取损失，如下所示： $$L^G_{dis}(x)=1-\u003c\\overline{f}^*(x),\\overline{f}(x)\u003e$$ 其中 $\\overline{f}^*(x)$ 和$ \\overline{f}(x)$ 分别是原始模型和当前模型提取的归一化特征。 ","date":"2021-05-13","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/:2:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Learning a Unified Classifier Incrementally via Rebalancing","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/"},{"categories":["论文笔记——深度学习"],"content":"Inter-Class Separation 为了避免新类和旧类之间的模糊性，LUCIR引入了一个边缘排序损失（margin ranking loss），以确保它们能够很好地分离： $$L_{mr}=\\sum_{k=1}^Kmax(m-\u003c\\overline{\\theta}(x),\\overline{f}(x)\u003e+\u003c\\overline{\\theta}^k,\\overline{f}(x)\u003e,0)$$ 其中$m$是边缘阈值，$\\overline{θ}(x)$是$x$的ground-truth class embedding，$θ^k$是被选为$x$的hard negatives的top-k个新类嵌入之一。 ","date":"2021-05-13","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/:3:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Learning a Unified Classifier Incrementally via Rebalancing","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/"},{"categories":["论文笔记——深度学习"],"content":"Integrated Objective $$L=\\frac{1}{N}\\sum_{x\\in N}(L_{ce}(x)+\\lambda L_{dis}^G(x))+\\frac{1}{N_0}\\sum{x \\in N_0}L_{mr}(x)$$ 其中，N是 $\\chi$ 中抽取的训练批次，$N_o \\subset N$是样例集，$\\lambda=\\lambda_{base}\\sqrt{|C_n|/|C_o|}$ 是损失权重（$\\lambda_{base}$是每个数据集的固定常量，$|C|$是类别数目） 实验 本文对于平衡性的分析比较全面，即考虑全连接层的偏置，又考虑特征蒸馏时的损失，同时还指出了新旧类之间存在模糊。针对这三个问题，LUCIR分别提出了三种损失函数作为约束。放缩性研究部分证明了各个损失项的有效性。不过提升比较有限，这部分的研究值得继续深挖。（当然，在样例集有限的前提下，这样的深挖也是有极限的） ","date":"2021-05-13","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/:4:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Learning a Unified Classifier Incrementally via Rebalancing","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于 CVPR 2020，参考代码见此。 本文主要做了两方面工作：其一，分析了知识蒸馏（Knowing Distillation）在增量学习中实际发挥的效果，提出KD的效果在于强调了旧类的差异性；其二，探究了新旧类不平衡的原因，提出了Weight Aligning维护公平性。 具体而言，table 1 表明施加KD增加了旧类被错分为新类的概率，降低了旧类被误分为其他旧类的概率。本文对此给出的解释是——KD维护了旧类的差异性。 传统观点中，KD的主要作用在于维护旧知识——以旧模型的输出作为标签来约束模型训练，从而在宏观中维护旧知识。本文在此基础上进一步从细节上探究了KD发挥的效果，最后通过旧类别被误分为其他旧类和新类的情况推得KD维护了新旧类的差异性。因为KD的施加降低了旧类被误分为其他旧类的概率（强调了旧类间的差异，维护了模型的旧知识），增加了旧类被误分为新类的概率（被误分为其他旧类的损失相较于被误分为新类的损失更大，且由于新旧类不平衡问题导致了对新类的响应高于对旧类响应） 不过这样的分析似乎并不全面，观察 Table 1 不难发现，KD损失的引入增大了新类的error，降低了旧类的error，由此可见KD同时维护了新旧类的公平性。 上图是在进行增量训练时，分类层权重范，观察到新类的权重范数明显大于旧类，由此推知训练过程中发生了不平衡，分类结果朝着新类倾斜。对此，本文提出了一个放缩因子来缩小新类权重的值，从而维护公平性。其公式如下： $$\\hat{W}{new}=\\gamma W{new}$$ $$\\gamma=\\frac{Mean(Norm_{old})}{Mean(Norm_{new})}$$ 模型结构 模型：For CIFAR-100, use 32-layer ResNet; For ImageNet, use 18-layer ResNet WA 模型的特点是使用线性纠正对$W_n$进行了缩放，以此来解决新旧类之间不平衡问题。 实验结果 ","date":"2021-05-12","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Maintaining Discrimination and Fairness in Class Incremental Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/"},{"categories":["论文笔记——深度学习"],"content":"简介 本文发表于CVPR 2019，代码见此。 本文在回溯策略上同 iCaRL 一样遵循了 herding 策略，主要致力于解决 rehearsal strategy 中新旧类不平衡问题，提出在全连接层后面增加偏置纠正（Bias Correction，简称BIC）。其公式如下： $$q_k=\\begin{cases} o_k \u0026 1 \\leqslant k \\leqslant n \\ \\alpha o_k+\\beta \u0026 n+1 \\leqslant k \\leqslant n + m \\end{cases}$$ 式中，$o_k$代表全连接层输出的logits，$\\alpha$和$\\beta$是可学习的偏置参数。当优化偏置参数时，本文冻结了特征提取层和全连接层使用一个很小validation set（从所有可获得的样本中分割出来的部分，保证新旧类样本平衡）来调整偏置参数，其损失函数如下： $$L_b=-\\sum_{k=1}^{n+m} \\delta_{y=k}log[softmax(q_k)]$$ 按照原文描述，之所以选择筛选出validation set用以偏执纠正层的学习，是为了将validation set从特征表示中排除，这或能使其更好的代表新旧类之间在特征空间上的无偏分布。当然，为了保证纠正层训练的无偏性，validation set中新旧类的数据量需要保持平衡。 原本在 Fig 5 中使用了 may better，这样的用词颇为鸡贼，这说明作者无法确定（或无法证明）validation set是否可以保证无偏。另一方面，validation set保证无偏对于最终的结果似乎并非好事，因为在此前的表示学习中由于新旧数据不平衡的问题，模型已经偏向了新类。因此，纠正的时候与其强调无偏，更应该强调将表示学习中的偏置给纠正回来。 这或许也说明了BIC为何在CIFAR100上最终效果几无提升。 模型结构 实验结果 (备注：ImageNet准确率高是因为取的是Top-5准确率) 从上述实验结果不难看出，BIC在小数据集如CIFAR上的提升几乎没有，但在ImageNet这样大数据集上却有比较明显的提升。作者们因此认为BIC更适合于Large Scale数据集。 但实际上，在ImageNet上所采用的是Top-5准确率（有些离谱的是top-5并没有在原文中出现，笔者是在对应代码的描述中确定的），这样的评价标准虽然可以表明BIC使预测更接近真实的结果，却并不能代表实际的准确率。 ","date":"2021-04-22","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/:0:0","tags":["incremental learning","rehearsal strategy"],"title":"论文笔记——Large Scale Incremental Learning","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/"},{"categories":["论文笔记——深度学习"],"content":"本文旨在总结诸如Selective Search、R-CNN等对象识别方法的主要思想。 ","date":"2019-07-23","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/:0:0","tags":["object detection"],"title":"Some methods of Object Recognition","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/"},{"categories":["论文笔记——深度学习"],"content":"Selctive Search 该方法的目的是对象识别，也就是说在一张图片里找出对象所在的区域，并识别他。其主要思想：先利用已知的、计算复杂度较低的一种算法将原图片划分为很多个小型区域，之后计算一个区与其领域的相关性，若相关性满足初始设置好的阈值，则将二者合并，遍历的进行这一操作，直到无法合并为止。并在此过程中，对每一个区域进行对象识别，若成功找到对象则保留结果。 优势：提供了一种Object detection的思路。 不足：主要有二。其一，由于区域合并之后会对新的区域再次进行识别（这一过程涉及计算），所以会不可避免的出现重复计算的情况。其二，有可能出现下一次标记的区域识别出来的对象正是上一次已经识别出的对象，且缺乏有效手段将之分离。 ","date":"2019-07-23","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/:1:0","tags":["object detection"],"title":"Some methods of Object Recognition","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/"},{"categories":["论文笔记——深度学习"],"content":"R-CNN 此方法在Selective Search的基础上，将特征提取层变为了卷积层，同时对于大小不等的Object Proposals采取了warpped的方法，使其以固定尺寸输入进卷积层并提取特征。 优势：卷积层提取特征的能力更加强大 不足：使用wrapped处理Object Proposals不可避免的会队原始图像进行诸如压缩、拉伸等操作，很大可能会出现信息失真。 ","date":"2019-07-23","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/:2:0","tags":["object detection"],"title":"Some methods of Object Recognition","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/"},{"categories":["论文笔记——深度学习"],"content":"Spatial Pryamid Pooling (SSP) 此方法相较于R-CNN最大的区别在于，不在输入图像时采取wrapped或者cropped的方法，而是直接将图像输入进卷积层，并在卷积层最后接上一个SPP层，SPP层会对最后一个卷积操作输出的feature maps进行处理，同样是对其进行卷积操作，至于其卷积核的尺寸和步长则需要根据相应的feature maps的尺寸作出调整。假设feature maps传入的是一个mxn的矩阵，则相应的，卷积核的尺寸为($⌈m/a⌉$, $⌈n/a$⌉)，步长为($⌊a/n⌋$)。($⌈⌉$指向上取整，$⌊⌋$指向下取整) 优势：可以把任意尺寸的图像作为输入。 不足：直接把运用Selective Search获得的Object Proposals输入进卷积层，会对许多特征进行重复提取，使得计算效率变差。 ","date":"2019-07-23","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/:3:0","tags":["object detection"],"title":"Some methods of Object Recognition","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/"},{"categories":["论文笔记——深度学习"],"content":"Fast R-CNN 结合了SSP和R-CNN，首先还是对原始图像进行Selective Serach得到Object Proposals，然后把原始图像输入进卷积层提取得到feature maps，从feature maps中选择与Object Proposals相对应的区域传入RoI(Region of Interest,其实质就是SPP层)。 优势：由于是直接利用原始图片进行特征提取，所以避免了出现重复提取特征的情况，极大的加快了计算效率。 不足：基本还是在Selective Search的基础上进行扩展，然而Selective Search本身需要花费大量计算时间。 ","date":"2019-07-23","objectID":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/:4:0","tags":["object detection"],"title":"Some methods of Object Recognition","uri":"/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0some_methods_of_obeject_detection/"}]