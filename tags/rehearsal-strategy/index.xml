<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>rehearsal strategy - 标签 - 大猫的博客</title>
        <link>https://capablecat.github.io/tags/rehearsal-strategy/</link>
        <description>rehearsal strategy - 标签 - 大猫的博客</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>krio_d@protonmail.com (大猫)</managingEditor>
            <webMaster>krio_d@protonmail.com (大猫)</webMaster><lastBuildDate>Tue, 27 Jul 2021 20:10:00 &#43;0800</lastBuildDate><atom:link href="https://capablecat.github.io/tags/rehearsal-strategy/" rel="self" type="application/rss+xml" /><item>
    <title>论文笔记——Training Networks in Null Space of Feature Covariance for Continual Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</link>
    <pubDate>Tue, 27 Jul 2021 20:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。（本文是西交数学与统计学院发表的文章，数学方面比较硬核） 本文专注于连续训练时不访问之前的数据。本]]></description>
</item><item>
    <title>论文笔记——Prototype Augmentation and Self-Supervision for Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</link>
    <pubDate>Tue, 27 Jul 2021 14:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。 本文指出了增量学习过程中 task-level overfitting phenomenon。直观上，这是说模型在训练当前任务的时候，只会专]]></description>
</item><item>
    <title>论文笔记——Rainbow Memory: Continual Learning with a Memory of Diverse Samples</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/</link>
    <pubDate>Tue, 20 Jul 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0rainbow-memory-continual-learning-with-a-memory-of-diverse-samples/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2021，代码见此。 本文聚焦于 rehearsal 策略中样本筛选问题，作者认为，被选择存储在内存中的样本不仅应该代表它们对应的类别，而且应该区]]></description>
</item><item>
    <title>论文笔记——DER: Dynamically Expandable Representation for Class Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</link>
    <pubDate>Thu, 24 Jun 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0der/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2021，随文代码在这里。 本文主要基于 architectural strategy，设计了一种动态扩充网络模型的方法。同时，该方法也采用了 rehearsal strategy 保]]></description>
</item><item>
    <title>论文笔记——Mnemonics Training: Multi-Class Incremental Learning without Forgetting</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</link>
    <pubDate>Mon, 07 Jun 2021 01:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0mnemonics-training/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2020，代码在这里。 本文基于 Rehearsal strategy，从改进样例集的角度出发提出了 Mnemonics Training。他们把旧样例集（exemp]]></description>
</item><item>
    <title>论文笔记——iCaRL: Incremental Classifier and Representation Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</link>
    <pubDate>Mon, 17 May 2021 12:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0icarl/</guid>
    <description><![CDATA[简介 本文是增量学习的经典论文，发表于CVPR 2017，基于pytorch的代码在此处。 本文是rehearsal策略的经典算法，其核心点主要是]]></description>
</item><item>
    <title>论文笔记——Learning a Unified Classifier Incrementally via Rebalancing</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/</link>
    <pubDate>Thu, 13 May 2021 12:15:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0learning-a-unified-classifier-incrementally-via-rebalancing/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2019，复现代码见此。 LUCIR同样是致力于缓解rehearsal中不平衡问题，如 Fig.1 所示，本文指出不平衡的数据主要带]]></description>
</item><item>
    <title>论文笔记——Maintaining Discrimination and Fairness in Class Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/</link>
    <pubDate>Wed, 12 May 2021 08:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0maintaining-discrimination-and-fairness/</guid>
    <description><![CDATA[简介 本文发表于 CVPR 2020，参考代码见此。 本文主要做了两方面工作：其一，分析了知识蒸馏（Knowing Distillation）在增量学习中实]]></description>
</item><item>
    <title>论文笔记——Large Scale Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/</link>
    <pubDate>Thu, 22 Apr 2021 11:32:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0large-scale-incremental-learning/</guid>
    <description><![CDATA[简介 本文发表于CVPR 2019，代码见此。 本文在回溯策略上同 iCaRL 一样遵循了 herding 策略，主要致力于解决 rehearsal strategy 中新旧类不平衡问题，提出在全连接层后面增加]]></description>
</item></channel>
</rss>
