<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>self-supervised learning - 标签 - 大猫的博客</title>
        <link>https://capablecat.github.io/tags/self-supervised-learning/</link>
        <description>self-supervised learning - 标签 - 大猫的博客</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>krio_d@protonmail.com (大猫)</managingEditor>
            <webMaster>krio_d@protonmail.com (大猫)</webMaster><lastBuildDate>Tue, 27 Jul 2021 20:10:00 &#43;0800</lastBuildDate><atom:link href="https://capablecat.github.io/tags/self-supervised-learning/" rel="self" type="application/rss+xml" /><item>
    <title>论文笔记——Training Networks in Null Space of Feature Covariance for Continual Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</link>
    <pubDate>Tue, 27 Jul 2021 20:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0training-networks-in-null-space-of-feature-covariance-for-continual-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。（本文是西交数学与统计学院发表的文章，数学方面比较硬核） 本文专注于连续训练时不访问之前的数据。本]]></description>
</item><item>
    <title>论文笔记——Prototype Augmentation and Self-Supervision for Incremental Learning</title>
    <link>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</link>
    <pubDate>Tue, 27 Jul 2021 14:10:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://capablecat.github.io/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0prototype-augmentation-and-self-supervision-for-incremental-learning/</guid>
    <description><![CDATA[一、简介 本文发表于 CVPR 2021，随文代码见此。 本文指出了增量学习过程中 task-level overfitting phenomenon。直观上，这是说模型在训练当前任务的时候，只会专]]></description>
</item></channel>
</rss>
